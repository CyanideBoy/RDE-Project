{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package punkt to /nfs4/ushashi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from model import ConvNet_Shallow_Single as ConvNet_SS\n",
    "from model import ConvNet \n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "import fasttext.CustomDataset as CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 - World\n",
      "1 - Sports\n",
      "2 - Business\n",
      "3 - Sci/Tech\n",
      "\n",
      "23848\n",
      "Printing Train + Val Number of Documents Found\n",
      "120000\n"
     ]
    }
   ],
   "source": [
    "LEARNINGRATE = 3e-3\n",
    "GAMMA = 0.98\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "NUMEPOCHS = 12\n",
    "\n",
    "\n",
    "dset = CustomDataset.get_dataset('data/train.csv')\n",
    "tset = CustomDataset.get_dataset('data/test.csv')\n",
    "\n",
    "print('''\n",
    "0 - World\n",
    "1 - Sports\n",
    "2 - Business\n",
    "3 - Sci/Tech\n",
    "''')\n",
    "\n",
    "### TRAIN VAL SPLIT\n",
    "\n",
    "NUM_DATA_POINTS = len(dset)\n",
    "\n",
    "indices = list(range(NUM_DATA_POINTS))\n",
    "split = int(np.floor(0.2 * NUM_DATA_POINTS))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(indices[0])\n",
    "\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_points = len(train_indices)\n",
    "val_points = len(val_indices)\n",
    "            \n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE, \n",
    "                                           sampler=train_sampler, num_workers=4)\n",
    "validation_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE,\n",
    "                                                sampler=valid_sampler, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(tset, batch_size = BATCHSIZE,\n",
    "                                                num_workers=4)\n",
    "\n",
    "print(\"Printing Train + Val Number of Documents Found\")\n",
    "print(NUM_DATA_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Slave model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "---Printing Parameters Finished!---\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_slave = ConvNet_SS(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Slave model..')\n",
    "model_slave.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/sw-2/Model_best_val_quicksave.pt'\n",
    "\n",
    "model_slave.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model_slave.eval()\n",
    "\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model_slave.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model_slave.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "print('---Printing Parameters Finished!---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n",
      "---Printing Parameters Finished!---\n"
     ]
    }
   ],
   "source": [
    "model_master = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model_master.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE_MASTER = 'fasttext/weights_2/Model_quicksave5.pt'\n",
    "\n",
    "model_master.load_state_dict(torch.load(FILE_MASTER,map_location='cuda:0'))\n",
    "model_master.eval()\n",
    "\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model_master.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        #print(param.shape)\n",
    "print('---Printing Parameters Finished!---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Slave: 81.08%\n"
     ]
    }
   ],
   "source": [
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model_slave(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy Slave: {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Master: 91.12%\n"
     ]
    }
   ],
   "source": [
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model_master(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy Master: {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "['conv1' 'fc1' 'fc2' 'fc3']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 300, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, 1, 1024)     922624    \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,193,380\n",
      "Trainable params: 1,193,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from keras.layers import Conv2D, Input, Dense, MaxPool2D, Flatten, Lambda, GlobalMaxPool2D, Dropout\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import innvestigate\n",
    "import innvestigate.applications\n",
    "import innvestigate.applications.mnist\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.utils.tests.networks import base as network_base\n",
    "\n",
    "print(K.image_data_format())\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    inp = Input((None,300,1))\n",
    "    x = Conv2D(1024,(3,300),activation='relu', name='conv1')(inp)\n",
    "    x = GlobalMaxPool2D('channels_last')(x)\n",
    "    x = Dense(256,name='fc1',activation='relu')(x)\n",
    "    z = Dropout(0.25)(x)\n",
    "    ou = Dense(32,name='fc2',activation='relu')(z)\n",
    "    ou = Dropout(0.3)(ou)\n",
    "    out = Dense(4,name='fc3')(ou)\n",
    "    outz = Dropout(0.2)(out)\n",
    "    k_model = Model(inp, outz)\n",
    "\n",
    "\n",
    "trained_weights = model_master.state_dict()\n",
    "\n",
    "pytorch_layers = [] # get ptroch layers names and suffixes\n",
    "for x, l in zip(trained_weights, k_model.layers):\n",
    "    pytorch_layers.append(x[:x.find('.')])\n",
    "\n",
    "unique_layers = np.unique(pytorch_layers)\n",
    "print(unique_layers)\n",
    "\n",
    "\n",
    "for layer in unique_layers:\n",
    "    weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "    biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "    if 'bn' in layer:\n",
    "        running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "        running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "        W = [weights, biases, running_mean, running_var]\n",
    "    elif 'fc' in layer:\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        W = [weights.T, biases]\n",
    "    else:\n",
    "        W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "    k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "k_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "method = (\"lrp.z\",{},\"LRP-Z\")\n",
    "         \n",
    "analyzer = innvestigate.create_analyzer(method[0], k_model,neuron_selection_mode=\"index\",**method[1]) #neuron_selection_mode=\"index\",  \n",
    "\n",
    "\n",
    "analyzis = [None]*train_points\n",
    "\n",
    "for i in range(train_points):\n",
    " \n",
    "    index = train_indices[i]\n",
    "    x = dset[index]['matrix']\n",
    "    y = dset[index]['class']\n",
    "    x = x.reshape((1, -1, 300,1)).numpy()    \n",
    "    analyzis[i] = np.zeros(x.shape[1])\n",
    "    \n",
    "    a = np.squeeze(analyzer.analyze(x,neuron_selection=y))\n",
    "    a = np.sum(a, axis=1)\n",
    "    analyzis[i] = a   \n",
    "\n",
    "np.save('lrp_maps_training_for_MS.npy',analyzis)\n",
    "'''\n",
    "analyzis = np.load('lrp_maps_training_for_MS.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  512\n",
      "epoch [1/12] Forced Epoch loss:0.9930135, train acc:59.2452, val loss:0.6342847, val acc:77.2583 in 0h 4m 35s\n",
      "epoch [2/12] Unforced Epoch loss:0.7069531, train acc:71.7208, val loss:0.5731792, val acc:80.9542 in 0h 0m 47s\n",
      "epoch [3/12] Forced Epoch loss:0.9291499, train acc:60.4650, val loss:0.6473239, val acc:76.5917 in 0h 4m 36s\n",
      "epoch [4/12] Unforced Epoch loss:0.7225628, train acc:71.0812, val loss:0.5845382, val acc:80.8875 in 0h 0m 48s\n",
      "epoch [5/12] Forced Epoch loss:0.9244480, train acc:60.5449, val loss:0.6434335, val acc:77.0500 in 0h 4m 36s\n",
      "epoch [6/12] Unforced Epoch loss:0.7237775, train acc:71.2719, val loss:0.5840808, val acc:80.8458 in 0h 0m 47s\n",
      "epoch [7/12] Forced Epoch loss:0.9198702, train acc:60.8284, val loss:0.6418323, val acc:77.0500 in 0h 4m 36s\n",
      "epoch [8/12] Unforced Epoch loss:0.7231797, train acc:71.3146, val loss:0.5847844, val acc:80.8417 in 0h 0m 47s\n",
      "epoch [9/12] Forced Epoch loss:0.9185647, train acc:60.7527, val loss:0.6469868, val acc:76.8542 in 0h 4m 39s\n",
      "epoch [10/12] Unforced Epoch loss:0.7217602, train acc:71.2313, val loss:0.5852224, val acc:80.8667 in 0h 0m 47s\n",
      "epoch [11/12] Forced Epoch loss:0.9161089, train acc:60.9003, val loss:0.6432501, val acc:77.0750 in 0h 4m 36s\n",
      "epoch [12/12] Unforced Epoch loss:0.7221251, train acc:71.1604, val loss:0.5842383, val acc:80.8500 in 0h 0m 47s\n"
     ]
    }
   ],
   "source": [
    "top_n = 6\n",
    "\n",
    "fraction_zeroed = 5 #(out of 8) \n",
    "num = fraction_zeroed\n",
    "\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "BATCHSIZE = 8*64\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model_slave.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    \n",
    "    if epoch%2 == 1:\n",
    "        mode = 'Forced Epoch'\n",
    "        for i in range((train_points)//64):\n",
    "            \n",
    "            #if i%100==0:\n",
    "            #    print(i)\n",
    "            \n",
    "            data_input = np.zeros((BATCHSIZE,1,80,300))\n",
    "            data_output = np.zeros(BATCHSIZE)\n",
    "            \n",
    "            for j in range(64):\n",
    "                index = train_indices[64*i+j]\n",
    "                sample = dset[index]\n",
    "            \n",
    "                data = sample['matrix'][None,None,:,:].numpy()\n",
    "                data = np.tile(data,(8,1,1,1))\n",
    "                \n",
    "                order = np.argsort(analyzis[i])[::-1]\n",
    "                data[:num,:,order[top_n:],:] = np.zeros((num,1,80-top_n,300)) ##Other words removed in num/8 batches \n",
    "                \n",
    "                data_input[j*8:(j+1)*8] = data\n",
    "                \n",
    "                data = sample['class'][0].numpy()\n",
    "                data = np.tile(data,(8))\n",
    "                \n",
    "                data_output[j*8:(j+1)*8] = data\n",
    "            \n",
    "            data_input = torch.as_tensor(data_input)\n",
    "            data_output = torch.as_tensor(data_output)\n",
    "            \n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model_slave(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= (train_points*8) \n",
    "        tacc = tacc*100.0/ (train_points*8)\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "        \n",
    "        \n",
    "    if epoch%2 == 0:    \n",
    "        mode = 'Unforced Epoch'\n",
    "        for ib,sample in enumerate(train_loader):\n",
    "\n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model_slave(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= train_points \n",
    "        tacc = tacc*100.0/ train_points\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "    \n",
    "    model_slave.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model_slave(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model_slave.state_dict(), 'fasttext/integrated_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model_slave.state_dict(), 'fasttext/integrated_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(np.array(loss_values_train), 'b')\n",
    "plt.plot(np.array(loss_values_val), 'r')\n",
    "plt.legend(['Train','Val'])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Slave: 80.20%\n"
     ]
    }
   ],
   "source": [
    "model_slave.eval()\n",
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model_slave(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy Slave: {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Slave model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "---Printing Parameters Finished!---\n"
     ]
    }
   ],
   "source": [
    "model_slave = ConvNet_SS(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Slave model..')\n",
    "model_slave.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/sw-2/Model_best_val_quicksave.pt'\n",
    "\n",
    "model_slave.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model_slave.eval()\n",
    "\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model_slave.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model_slave.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "print('---Printing Parameters Finished!---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  1024\n",
      "epoch [1/12] Forced Epoch loss:1.6659623, train acc:41.3417, val loss:1.2623117, val acc:61.5042 in 0h 0m 48s\n",
      "epoch [2/12] Unforced Epoch loss:0.7692478, train acc:69.9240, val loss:0.5253153, val acc:81.2292 in 0h 0m 47s\n",
      "epoch [3/12] Forced Epoch loss:1.5095028, train acc:44.6240, val loss:1.3422550, val acc:61.0917 in 0h 0m 48s\n",
      "epoch [4/12] Unforced Epoch loss:0.7744736, train acc:70.2031, val loss:0.5366828, val acc:81.0250 in 0h 0m 48s\n",
      "epoch [5/12] Forced Epoch loss:1.4183003, train acc:45.3260, val loss:1.3348118, val acc:61.3542 in 0h 0m 48s\n",
      "epoch [6/12] Unforced Epoch loss:0.7645391, train acc:70.3740, val loss:0.5419775, val acc:81.0958 in 0h 0m 47s\n",
      "epoch [7/12] Forced Epoch loss:1.3525089, train acc:46.1250, val loss:1.2456023, val acc:61.8208 in 0h 0m 47s\n",
      "epoch [8/12] Unforced Epoch loss:0.7580448, train acc:70.3063, val loss:0.5470334, val acc:81.0167 in 0h 0m 47s\n",
      "epoch [9/12] Forced Epoch loss:1.3089666, train acc:46.3802, val loss:1.2176342, val acc:61.6042 in 0h 0m 48s\n",
      "epoch [10/12] Unforced Epoch loss:0.7574974, train acc:70.4375, val loss:0.5557250, val acc:81.1042 in 0h 0m 47s\n",
      "epoch [11/12] Forced Epoch loss:1.2789257, train acc:46.7896, val loss:1.1943830, val acc:60.4083 in 0h 0m 47s\n",
      "epoch [12/12] Unforced Epoch loss:0.7536501, train acc:70.3854, val loss:0.5589631, val acc:80.9250 in 0h 0m 47s\n"
     ]
    }
   ],
   "source": [
    "top_n = 3\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model_slave.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    \n",
    "    if epoch%2 == 1:\n",
    "        mode = 'Forced Epoch'\n",
    "        for i,sample in enumerate(train_loader):\n",
    "            \n",
    "            data_input = sample['matrix'][:,None,:,:].numpy()\n",
    "            data_output = sample['class'][:,0].numpy()\n",
    "            \n",
    "            for j in range(BATCHSIZE):\n",
    "                try:\n",
    "                    order = np.argsort(analyzis[BATCHSIZE*i+j])[::-1]\n",
    "                except IndexError as error:\n",
    "                    break\n",
    "                    \n",
    "                for k in order[top_n:]:\n",
    "                    data_input[j,:,k,:] = np.zeros((1,1,1,300)) \n",
    "                \n",
    "            \n",
    "            data_input = torch.as_tensor(data_input)\n",
    "            data_output = torch.as_tensor(data_output)\n",
    "            \n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model_slave(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= (train_points) \n",
    "        tacc = tacc*100.0/ (train_points)\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "        \n",
    "        \n",
    "    if epoch%2 == 0:    \n",
    "        mode = 'Unforced Epoch'\n",
    "        for ib,sample in enumerate(train_loader):\n",
    "\n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model_slave(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= train_points \n",
    "        tacc = tacc*100.0/ train_points\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "    \n",
    "    model_slave.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model_slave(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model_slave.state_dict(), 'fasttext/integrated-v2_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model_slave.state_dict(), 'fasttext/integrated-v2_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Slave: 80.87%\n"
     ]
    }
   ],
   "source": [
    "model_slave.eval()\n",
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model_slave(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy Slave: {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Slave model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "---Printing Parameters Finished!---\n"
     ]
    }
   ],
   "source": [
    "LEARNINGRATE = 5e-4\n",
    "GAMMA = 0.7\n",
    "NUMEPOCHS = 3\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_slave = ConvNet_SS(True, WINDOW=3, FEATURES=2)\n",
    "print('Running on',device)\n",
    "print('Building Slave model..')\n",
    "model_slave.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/sw-2/Model_best_val_quicksave.pt'\n",
    "\n",
    "model_slave.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model_slave.eval()\n",
    "\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model_slave.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model_slave.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "print('---Printing Parameters Finished!---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  1024\n",
      "epoch [1/3] Forced Epoch loss:1.8346004, train acc:37.2229, val loss:0.5548742, val acc:80.1417 in 0h 0m 48s\n",
      "epoch [2/3] Forced Epoch loss:1.7111905, train acc:40.4302, val loss:0.6742037, val acc:76.3375 in 0h 0m 48s\n",
      "epoch [3/3] Forced Epoch loss:1.6090052, train acc:42.7927, val loss:0.8378325, val acc:71.2125 in 0h 0m 48s\n"
     ]
    }
   ],
   "source": [
    "top_n = 3\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model_slave.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    \n",
    "    mode = 'Forced Epoch'\n",
    "    for i,sample in enumerate(train_loader):\n",
    "\n",
    "        data_input = sample['matrix'][:,None,:,:].numpy()\n",
    "        data_output = sample['class'][:,0].numpy()\n",
    "\n",
    "        for j in range(BATCHSIZE):\n",
    "            try:\n",
    "                order = np.argsort(analyzis[BATCHSIZE*i+j])[::-1]\n",
    "            except IndexError as error:\n",
    "                break\n",
    "\n",
    "            for k in order[top_n:]:\n",
    "                data_input[j,:,k,:] = np.zeros((1,1,1,300)) \n",
    "\n",
    "\n",
    "        data_input = torch.as_tensor(data_input)\n",
    "        data_output = torch.as_tensor(data_output)\n",
    "\n",
    "        data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "        data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "        output = model_slave(data_input) \n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        loss = criterion(output, data_output)\n",
    "        runloss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        runloss += loss.item() * data_input.size(0)\n",
    "        tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "    runloss /= (train_points) \n",
    "    tacc = tacc*100.0/ (train_points)\n",
    "\n",
    "    loss_values_train.append(runloss)\n",
    "    \n",
    "    model_slave.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model_slave(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model_slave.state_dict(), 'fasttext/integrated-v3_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model_slave.state_dict(), 'fasttext/integrated-v3_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Slave: 70.88%\n"
     ]
    }
   ],
   "source": [
    "model_slave.eval()\n",
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model_slave(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy Slave: {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_ptorch",
   "language": "python",
   "name": "gpu_ptorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
