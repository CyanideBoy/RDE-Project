{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /nfs4/ushashi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from model import ConvNet_Shallow_Single as ConvNet_SS\n",
    "from model import ConvNet \n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "import fasttext.CustomDataset as CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 - World\n",
      "1 - Sports\n",
      "2 - Business\n",
      "3 - Sci/Tech\n",
      "\n",
      "23848\n",
      "Printing Train + Val Number of Documents Found\n",
      "120000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "LEARNINGRATE = 3e-3\n",
    "GAMMA = 0.98\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "NUMEPOCHS = 20\n",
    "\n",
    "\n",
    "dset = CustomDataset.get_dataset('data/train.csv')\n",
    "tset = CustomDataset.get_dataset('data/test.csv')\n",
    "\n",
    "print('''\n",
    "0 - World\n",
    "1 - Sports\n",
    "2 - Business\n",
    "3 - Sci/Tech\n",
    "''')\n",
    "\n",
    "### TRAIN VAL SPLIT\n",
    "\n",
    "NUM_DATA_POINTS = len(dset)\n",
    "\n",
    "indices = list(range(NUM_DATA_POINTS))\n",
    "split = int(np.floor(0.2 * NUM_DATA_POINTS))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(indices[0])\n",
    "\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_points = len(train_indices)\n",
    "val_points = len(val_indices)\n",
    "            \n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE, \n",
    "                                           sampler=train_sampler, num_workers=4)\n",
    "validation_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE,\n",
    "                                                sampler=valid_sampler, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(tset, batch_size = BATCHSIZE,\n",
    "                                                num_workers=4)\n",
    "\n",
    "print(\"Printing Train + Val Number of Documents Found\")\n",
    "print(NUM_DATA_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Slave model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "---Printing Parameters Finished!---\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_slave = ConvNet_SS(True, WINDOW=3, FEATURES=2)\n",
    "print('Running on',device)\n",
    "print('Building Slave model..')\n",
    "model_slave.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/sw4-2/Model_best_val_quicksave.pt'\n",
    "\n",
    "model_slave.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model_slave.eval()\n",
    "\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model_slave.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model_slave.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "print('---Printing Parameters Finished!---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n",
      "---Printing Parameters Finished!---\n"
     ]
    }
   ],
   "source": [
    "model_master = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model_master.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE_MASTER = 'fasttext/weights_2/Model_quicksave5.pt'\n",
    "\n",
    "model_master.load_state_dict(torch.load(FILE_MASTER,map_location='cuda:0'))\n",
    "model_master.eval()\n",
    "\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model_master.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        #print(param.shape)\n",
    "print('---Printing Parameters Finished!---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Slave: 80.76%\n"
     ]
    }
   ],
   "source": [
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model_slave(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy Slave: {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Master: 91.12%\n"
     ]
    }
   ],
   "source": [
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model_master(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy Master: {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "['conv1' 'fc1' 'fc2' 'fc3']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 300, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, 1, 1024)     922624    \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,193,380\n",
      "Trainable params: 1,193,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from keras.layers import Conv2D, Input, Dense, MaxPool2D, Flatten, Lambda, GlobalMaxPool2D, Dropout\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import innvestigate\n",
    "import innvestigate.applications\n",
    "import innvestigate.applications.mnist\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.utils.tests.networks import base as network_base\n",
    "\n",
    "print(K.image_data_format())\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    inp = Input((None,300,1))\n",
    "    x = Conv2D(1024,(3,300),activation='relu', name='conv1')(inp)\n",
    "    x = GlobalMaxPool2D('channels_last')(x)\n",
    "    x = Dense(256,name='fc1',activation='relu')(x)\n",
    "    z = Dropout(0.25)(x)\n",
    "    ou = Dense(32,name='fc2',activation='relu')(z)\n",
    "    ou = Dropout(0.3)(ou)\n",
    "    out = Dense(4,name='fc3')(ou)\n",
    "    outz = Dropout(0.2)(out)\n",
    "    k_model = Model(inp, outz)\n",
    "\n",
    "\n",
    "trained_weights = model_master.state_dict()\n",
    "\n",
    "pytorch_layers = [] # get ptroch layers names and suffixes\n",
    "for x, l in zip(trained_weights, k_model.layers):\n",
    "    pytorch_layers.append(x[:x.find('.')])\n",
    "\n",
    "unique_layers = np.unique(pytorch_layers)\n",
    "print(unique_layers)\n",
    "\n",
    "\n",
    "for layer in unique_layers:\n",
    "    weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "    biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "    if 'bn' in layer:\n",
    "        running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "        running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "        W = [weights, biases, running_mean, running_var]\n",
    "    elif 'fc' in layer:\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        W = [weights.T, biases]\n",
    "    else:\n",
    "        W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "    k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "k_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = (\"lrp.z\",{},\"LRP-Z\")\n",
    "         \n",
    "analyzer = innvestigate.create_analyzer(method[0], k_model,**method[1]) #neuron_selection_mode=\"index\",  \n",
    "\n",
    "\n",
    "analyzis = [None]*train_points\n",
    "\n",
    "for i in range(train_points):\n",
    " \n",
    "    index = train_indices[i]\n",
    "    x = dset[index]['matrix']\n",
    "    x = x.reshape((1, -1, 300,1)).numpy()    \n",
    "    analyzis[i] = np.zeros(x.shape[1])\n",
    "    \n",
    "    a = np.squeeze(analyzer.analyze(x))\n",
    "    a = np.sum(a, axis=1)\n",
    "    analyzis[i] = a   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  512\n",
      "epoch [1/20] Forced Epoch loss:1.4852887, train acc:54.8501, val loss:0.6265151, val acc:77.1958 in 0h 3m 51s\n",
      "epoch [2/20] Unforced Epoch loss:1.1690961, train acc:66.2458, val loss:0.5590931, val acc:81.4125 in 0h 0m 42s\n",
      "epoch [3/20] Forced Epoch loss:1.4043189, train acc:56.4792, val loss:0.6408050, val acc:76.5250 in 0h 3m 50s\n",
      "epoch [4/20] Unforced Epoch loss:1.1905067, train acc:66.0354, val loss:0.5766430, val acc:81.1917 in 0h 0m 41s\n",
      "epoch [5/20] Forced Epoch loss:1.3985519, train acc:56.7142, val loss:0.6441042, val acc:76.4958 in 0h 3m 53s\n",
      "epoch [6/20] Unforced Epoch loss:1.1850844, train acc:66.1208, val loss:0.5774940, val acc:81.0542 in 0h 0m 41s\n",
      "epoch [7/20] Forced Epoch loss:1.3946758, train acc:56.8327, val loss:0.6540081, val acc:75.8875 in 0h 3m 52s\n",
      "epoch [8/20] Unforced Epoch loss:1.1901861, train acc:65.9302, val loss:0.5769474, val acc:81.2000 in 0h 0m 42s\n",
      "epoch [9/20] Forced Epoch loss:1.3935813, train acc:56.9632, val loss:0.6503567, val acc:76.5750 in 0h 4m 0s\n",
      "epoch [10/20] Unforced Epoch loss:1.1867857, train acc:66.0656, val loss:0.5773633, val acc:81.0833 in 0h 0m 42s\n",
      "epoch [11/20] Forced Epoch loss:1.3895407, train acc:57.0508, val loss:0.6526819, val acc:76.4167 in 0h 3m 57s\n",
      "epoch [12/20] Unforced Epoch loss:1.1840681, train acc:66.2583, val loss:0.5787075, val acc:81.2125 in 0h 0m 42s\n",
      "epoch [13/20] Forced Epoch loss:1.3899126, train acc:57.0626, val loss:0.6547911, val acc:76.5583 in 0h 3m 55s\n",
      "epoch [14/20] Unforced Epoch loss:1.1843245, train acc:66.2062, val loss:0.5789538, val acc:81.1083 in 0h 0m 42s\n",
      "epoch [15/20] Forced Epoch loss:1.3884780, train acc:57.1007, val loss:0.6474980, val acc:76.8625 in 0h 3m 56s\n",
      "epoch [16/20] Unforced Epoch loss:1.1858724, train acc:66.1375, val loss:0.5797595, val acc:81.2000 in 0h 0m 43s\n",
      "epoch [17/20] Forced Epoch loss:1.3874068, train acc:57.1530, val loss:0.6440654, val acc:76.8625 in 0h 3m 51s\n",
      "epoch [18/20] Unforced Epoch loss:1.1896757, train acc:66.0458, val loss:0.5793804, val acc:81.0500 in 0h 0m 42s\n",
      "epoch [19/20] Forced Epoch loss:1.3855875, train acc:57.2009, val loss:0.6447100, val acc:76.9083 in 0h 3m 51s\n",
      "epoch [20/20] Unforced Epoch loss:1.1846113, train acc:66.1948, val loss:0.5801468, val acc:81.1208 in 0h 0m 42s\n"
     ]
    }
   ],
   "source": [
    "top_n = 6\n",
    "\n",
    "fraction_zeroed = 5 #(out of 8) \n",
    "num = fraction_zeroed\n",
    "\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "BATCHSIZE = 8*64\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model_slave.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    \n",
    "    if epoch%2 == 1:\n",
    "        mode = 'Forced Epoch'\n",
    "        for i in range((train_points)//64):\n",
    "            \n",
    "            #if i%100==0:\n",
    "            #    print(i)\n",
    "            \n",
    "            data_input = np.zeros((BATCHSIZE,1,80,300))\n",
    "            data_output = np.zeros(BATCHSIZE)\n",
    "            \n",
    "            for j in range(64):\n",
    "                index = train_indices[64*i+j]\n",
    "                sample = dset[index]\n",
    "            \n",
    "                data = sample['matrix'][None,None,:,:].numpy()\n",
    "                data = np.tile(data,(8,1,1,1))\n",
    "                \n",
    "                order = np.argsort(analyzis[i])[::-1]\n",
    "                data[:num,:,order[top_n:],:] = np.zeros((num,1,80-top_n,300)) ##Other words removed in num/8 batches \n",
    "                \n",
    "                data_input[j*8:(j+1)*8] = data\n",
    "                \n",
    "                data = sample['class'][0].numpy()\n",
    "                data = np.tile(data,(8))\n",
    "                \n",
    "                data_output[j*8:(j+1)*8] = data\n",
    "            \n",
    "            data_input = torch.as_tensor(data_input)\n",
    "            data_output = torch.as_tensor(data_output)\n",
    "            \n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model_slave(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= (train_points*8) \n",
    "        tacc = tacc*100.0/ (train_points*8)\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "        \n",
    "        \n",
    "    if epoch%2 == 0:    \n",
    "        mode = 'Unforced Epoch'\n",
    "        for ib,sample in enumerate(train_loader):\n",
    "\n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model_slave(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= train_points \n",
    "        tacc = tacc*100.0/ train_points\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "    \n",
    "    model_slave.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model_slave(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model_slave.state_dict(), 'fasttext/integrated_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model_slave.state_dict(), 'fasttext/integrated_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(np.array(loss_values_train), 'b')\n",
    "plt.plot(np.array(loss_values_val), 'r')\n",
    "plt.legend(['Train','Val'])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('train_curve_MS-POS-v1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Slave: 80.32%\n"
     ]
    }
   ],
   "source": [
    "model_slave.eval()\n",
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model_slave(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy Slave: {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Slave model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "---Printing Parameters Finished!---\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_slave = ConvNet_SS(True, WINDOW=3, FEATURES=2)\n",
    "print('Running on',device)\n",
    "print('Building Slave model..')\n",
    "model_slave.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/sw4-2/Model_best_val_quicksave.pt'\n",
    "\n",
    "model_slave.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model_slave.eval()\n",
    "\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model_slave.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model_slave.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "print('---Printing Parameters Finished!---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  1024\n",
      "epoch [1/20] Forced Epoch loss:2.2153638, train acc:39.3271, val loss:1.1975212, val acc:61.4667 in 0h 0m 43s\n",
      "epoch [2/20] Unforced Epoch loss:1.2698040, train acc:63.6531, val loss:0.5357270, val acc:81.3000 in 0h 0m 42s\n",
      "epoch [3/20] Forced Epoch loss:2.0434048, train acc:41.3937, val loss:1.6181626, val acc:55.7833 in 0h 0m 42s\n",
      "epoch [4/20] Unforced Epoch loss:1.3106436, train acc:63.1083, val loss:0.5384618, val acc:81.3083 in 0h 0m 41s\n",
      "epoch [5/20] Forced Epoch loss:1.9472596, train acc:42.3135, val loss:1.6628250, val acc:54.9375 in 0h 0m 42s\n",
      "epoch [6/20] Unforced Epoch loss:1.2993075, train acc:63.2667, val loss:0.5400426, val acc:81.1500 in 0h 0m 41s\n",
      "epoch [7/20] Forced Epoch loss:1.8957355, train acc:42.6917, val loss:1.5859491, val acc:55.5958 in 0h 0m 42s\n",
      "epoch [8/20] Unforced Epoch loss:1.2878849, train acc:63.4240, val loss:0.5415564, val acc:81.1917 in 0h 0m 42s\n",
      "epoch [9/20] Forced Epoch loss:1.8506963, train acc:43.0625, val loss:1.4941867, val acc:57.5083 in 0h 0m 43s\n",
      "epoch [10/20] Unforced Epoch loss:1.2737953, train acc:63.6854, val loss:0.5426538, val acc:81.2167 in 0h 0m 42s\n",
      "epoch [11/20] Forced Epoch loss:1.8179082, train acc:43.2719, val loss:1.4474494, val acc:57.5042 in 0h 0m 43s\n",
      "epoch [12/20] Unforced Epoch loss:1.2697721, train acc:63.7437, val loss:0.5444880, val acc:81.2125 in 0h 0m 42s\n",
      "epoch [13/20] Forced Epoch loss:1.7892089, train acc:43.8490, val loss:1.3637267, val acc:59.3292 in 0h 0m 43s\n",
      "epoch [14/20] Unforced Epoch loss:1.2564896, train acc:63.9833, val loss:0.5463479, val acc:81.0083 in 0h 0m 42s\n",
      "epoch [15/20] Forced Epoch loss:1.7697344, train acc:44.0594, val loss:1.3137095, val acc:59.4708 in 0h 0m 42s\n",
      "epoch [16/20] Unforced Epoch loss:1.2463164, train acc:64.2552, val loss:0.5476066, val acc:81.2042 in 0h 0m 41s\n",
      "epoch [17/20] Forced Epoch loss:1.7576400, train acc:43.7302, val loss:1.2480862, val acc:61.0583 in 0h 0m 43s\n",
      "epoch [18/20] Unforced Epoch loss:1.2449523, train acc:64.2875, val loss:0.5498156, val acc:81.1958 in 0h 0m 41s\n",
      "epoch [19/20] Forced Epoch loss:1.7341554, train acc:44.3146, val loss:1.2210764, val acc:60.5125 in 0h 0m 42s\n",
      "epoch [20/20] Unforced Epoch loss:1.2376248, train acc:64.3635, val loss:0.5504407, val acc:81.1833 in 0h 0m 42s\n"
     ]
    }
   ],
   "source": [
    "top_n = 3\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model_slave.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    \n",
    "    if epoch%2 == 1:\n",
    "        mode = 'Forced Epoch'\n",
    "        for i,sample in enumerate(train_loader):\n",
    "            \n",
    "            data_input = sample['matrix'][:,None,:,:].numpy()\n",
    "            data_output = sample['class'][:,0].numpy()\n",
    "            \n",
    "            for j in range(BATCHSIZE):\n",
    "                try:\n",
    "                    order = np.argsort(analyzis[BATCHSIZE*i+j])[::-1]\n",
    "                except IndexError as error:\n",
    "                    break\n",
    "                    \n",
    "                for k in order[top_n:]:\n",
    "                    data_input[j,:,k,:] = np.zeros((1,1,1,300)) \n",
    "                \n",
    "            \n",
    "            data_input = torch.as_tensor(data_input)\n",
    "            data_output = torch.as_tensor(data_output)\n",
    "            \n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model_slave(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= (train_points) \n",
    "        tacc = tacc*100.0/ (train_points)\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "        \n",
    "        \n",
    "    if epoch%2 == 0:    \n",
    "        mode = 'Unforced Epoch'\n",
    "        for ib,sample in enumerate(train_loader):\n",
    "\n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model_slave(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= train_points \n",
    "        tacc = tacc*100.0/ train_points\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "    \n",
    "    model_slave.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model_slave(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model_slave.state_dict(), 'fasttext/integrated-v2_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model_slave.state_dict(), 'fasttext/integrated-v2_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Slave: 80.42%\n"
     ]
    }
   ],
   "source": [
    "model_slave.eval()\n",
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model_slave(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy Slave: {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Slave model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "---Printing Parameters Finished!---\n"
     ]
    }
   ],
   "source": [
    "LEARNINGRATE = 5e-4\n",
    "GAMMA = 0.5\n",
    "NUMEPOCHS = 3\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_slave = ConvNet_SS(True, WINDOW=3, FEATURES=2)\n",
    "print('Running on',device)\n",
    "print('Building Slave model..')\n",
    "model_slave.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/sw4-2/Model_best_val_quicksave.pt'\n",
    "\n",
    "model_slave.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model_slave.eval()\n",
    "\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model_slave.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model_slave.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "print('---Printing Parameters Finished!---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  1024\n",
      "epoch [1/3] Forced Epoch loss:2.4077012, train acc:36.9750, val loss:0.5436520, val acc:80.7333 in 0h 0m 43s\n",
      "epoch [2/3] Forced Epoch loss:2.3086784, train acc:38.1531, val loss:0.5894211, val acc:79.0708 in 0h 0m 43s\n",
      "epoch [3/3] Forced Epoch loss:2.2340938, train acc:39.1615, val loss:0.6426835, val acc:76.9708 in 0h 0m 42s\n"
     ]
    }
   ],
   "source": [
    "top_n = 3\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model_slave.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    \n",
    "    mode = 'Forced Epoch'\n",
    "    for i,sample in enumerate(train_loader):\n",
    "\n",
    "        data_input = sample['matrix'][:,None,:,:].numpy()\n",
    "        data_output = sample['class'][:,0].numpy()\n",
    "\n",
    "        for j in range(BATCHSIZE):\n",
    "            try:\n",
    "                order = np.argsort(analyzis[BATCHSIZE*i+j])[::-1]\n",
    "            except IndexError as error:\n",
    "                break\n",
    "\n",
    "            for k in order[top_n:]:\n",
    "                data_input[j,:,k,:] = np.zeros((1,1,1,300)) \n",
    "\n",
    "\n",
    "        data_input = torch.as_tensor(data_input)\n",
    "        data_output = torch.as_tensor(data_output)\n",
    "\n",
    "        data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "        data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "        output = model_slave(data_input) \n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        loss = criterion(output, data_output)\n",
    "        runloss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        runloss += loss.item() * data_input.size(0)\n",
    "        tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "    runloss /= (train_points) \n",
    "    tacc = tacc*100.0/ (train_points)\n",
    "\n",
    "    loss_values_train.append(runloss)\n",
    "    \n",
    "    model_slave.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model_slave(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model_slave.state_dict(), 'fasttext/integrated-v3_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model_slave.state_dict(), 'fasttext/integrated-v3_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Slave: 75.59%\n"
     ]
    }
   ],
   "source": [
    "model_slave.eval()\n",
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model_slave(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy Slave: {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_ptorch",
   "language": "python",
   "name": "gpu_ptorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
