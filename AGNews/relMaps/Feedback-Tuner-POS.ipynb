{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package punkt to /nfs4/ushashi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "        \n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from model import ConvNet_Shallow_Single as ConvNet_SS\n",
    "from model import ConvNet \n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "import fasttext.CustomDataset as CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 - World\n",
      "1 - Sports\n",
      "2 - Business\n",
      "3 - Sci/Tech\n",
      "\n",
      "23848\n",
      "Printing Train + Val Number of Documents Found\n",
      "120000\n"
     ]
    }
   ],
   "source": [
    "LEARNINGRATE = 9e-2\n",
    "GAMMA = 0.94\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "NUMEPOCHS = 20\n",
    "\n",
    "\n",
    "dset = CustomDataset.get_dataset('data/train.csv')\n",
    "tset = CustomDataset.get_dataset('data/test.csv')\n",
    "\n",
    "print('''\n",
    "0 - World\n",
    "1 - Sports\n",
    "2 - Business\n",
    "3 - Sci/Tech\n",
    "''')\n",
    "\n",
    "### TRAIN VAL SPLIT\n",
    "\n",
    "NUM_DATA_POINTS = len(dset)\n",
    "\n",
    "indices = list(range(NUM_DATA_POINTS))\n",
    "split = int(np.floor(0.2 * NUM_DATA_POINTS))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(indices[0])\n",
    "\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_points = len(train_indices)\n",
    "val_points = len(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE, \n",
    "                                           sampler=train_sampler, num_workers=4)\n",
    "validation_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE,\n",
    "                                                sampler=valid_sampler, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(tset, batch_size = BATCHSIZE,\n",
    "                                                num_workers=4)\n",
    "\n",
    "print(\"Printing Train + Val Number of Documents Found\")\n",
    "print(NUM_DATA_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n",
      "---Printing Parameters Finished!---\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/weights_2/Model_quicksave5.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model.eval()\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        #print(param.shape)\n",
    "print('---Printing Parameters Finished!---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 91.12%\n"
     ]
    }
   ],
   "source": [
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "['conv1' 'fc1' 'fc2' 'fc3']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 300, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, 1, 1024)     922624    \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,193,380\n",
      "Trainable params: 1,193,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from keras.layers import Conv2D, Input, Dense, MaxPool2D, Flatten, Lambda, GlobalMaxPool2D, Dropout\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import innvestigate\n",
    "import innvestigate.applications\n",
    "import innvestigate.applications.mnist\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.utils.tests.networks import base as network_base\n",
    "\n",
    "print(K.image_data_format())\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    inp = Input((None,300,1))\n",
    "    x = Conv2D(1024,(3,300),activation='relu', name='conv1')(inp)\n",
    "    x = GlobalMaxPool2D('channels_last')(x)\n",
    "    x = Dense(256,name='fc1',activation='relu')(x)\n",
    "    z = Dropout(0.25)(x)\n",
    "    ou = Dense(32,name='fc2',activation='relu')(z)\n",
    "    ou = Dropout(0.3)(ou)\n",
    "    out = Dense(4,name='fc3')(ou)\n",
    "    outz = Dropout(0.2)(out)\n",
    "    k_model = Model(inp, outz)\n",
    "\n",
    "\n",
    "trained_weights = model.state_dict()\n",
    "\n",
    "pytorch_layers = [] # get ptroch layers names and suffixes\n",
    "for x, l in zip(trained_weights, k_model.layers):\n",
    "    pytorch_layers.append(x[:x.find('.')])\n",
    "\n",
    "unique_layers = np.unique(pytorch_layers)\n",
    "print(unique_layers)\n",
    "\n",
    "\n",
    "for layer in unique_layers:\n",
    "    weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "    biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "    if 'bn' in layer:\n",
    "        running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "        running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "        W = [weights, biases, running_mean, running_var]\n",
    "    elif 'fc' in layer:\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        W = [weights.T, biases]\n",
    "    else:\n",
    "        W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "    k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "k_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(train_points):\\n \\n    index = train_indices[i]\\n    x = dset[index]['matrix']\\n    x = x.reshape((1, -1, 300,1)).numpy()    \\n    analyzis[i] = np.zeros(x.shape[1])\\n    \\n    a = np.squeeze(analyzer.analyze(x))\\n    a = np.sum(a, axis=1)\\n    analyzis[i] = a   \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = (\"lrp.z\",{},\"LRP-Z\")\n",
    "         \n",
    "analyzer = innvestigate.create_analyzer(method[0], k_model,neuron_selection_mode=\"index\",**method[1]) #neuron_selection_mode=\"index\",  \n",
    "\n",
    "'''\n",
    "for i in range(train_points):\n",
    " \n",
    "    index = train_indices[i]\n",
    "    x = dset[index]['matrix']\n",
    "    x = x.reshape((1, -1, 300,1)).numpy()    \n",
    "    analyzis[i] = np.zeros(x.shape[1])\n",
    "    \n",
    "    a = np.squeeze(analyzer.analyze(x))\n",
    "    a = np.sum(a, axis=1)\n",
    "    analyzis[i] = a   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  1024\n",
      "epoch [1/20] Forced Epoch loss:0.1905525, train acc:91.9938, val loss:0.7089024, val acc:74.5750 in 0h 3m 49s\n",
      "epoch [2/20] Unforced Epoch loss:0.7448123, train acc:72.0583, val loss:0.3618880, val acc:88.6167 in 0h 0m 47s\n",
      "epoch [3/20] Forced Epoch loss:0.3007249, train acc:87.9292, val loss:0.8104240, val acc:66.9792 in 0h 3m 47s\n",
      "epoch [4/20] Unforced Epoch loss:0.8763014, train acc:64.2510, val loss:0.7563542, val acc:66.8833 in 0h 0m 47s\n",
      "epoch [5/20] Forced Epoch loss:2.0701953, train acc:55.2198, val loss:8.1546615, val acc:24.7833 in 0h 3m 46s\n",
      "epoch [6/20] Unforced Epoch loss:1.9857807, train acc:25.1104, val loss:1.3863054, val acc:25.1250 in 0h 0m 48s\n",
      "epoch [7/20] Forced Epoch loss:1.3879605, train acc:24.9427, val loss:1.3863768, val acc:24.8667 in 0h 3m 46s\n",
      "epoch [8/20] Unforced Epoch loss:1.3878124, train acc:24.8198, val loss:1.3865432, val acc:25.0917 in 0h 0m 48s\n",
      "epoch [9/20] Forced Epoch loss:1.3879456, train acc:25.0365, val loss:1.3865383, val acc:25.1250 in 0h 3m 47s\n",
      "epoch [10/20] Unforced Epoch loss:1.3880842, train acc:25.0437, val loss:1.3864721, val acc:25.0917 in 0h 0m 47s\n",
      "epoch [11/20] Forced Epoch loss:1.3879464, train acc:24.8510, val loss:1.3864863, val acc:25.0917 in 0h 3m 46s\n",
      "epoch [12/20] Unforced Epoch loss:1.3882127, train acc:24.7417, val loss:1.3867295, val acc:25.0917 in 0h 0m 47s\n",
      "epoch [13/20] Forced Epoch loss:1.3881149, train acc:25.1177, val loss:1.3863096, val acc:24.9167 in 0h 3m 46s\n",
      "epoch [14/20] Unforced Epoch loss:1.3879657, train acc:25.0188, val loss:1.3865957, val acc:24.8667 in 0h 0m 48s\n",
      "epoch [15/20] Forced Epoch loss:1.3879385, train acc:24.9312, val loss:1.3864396, val acc:25.0917 in 0h 3m 47s\n",
      "epoch [16/20] Unforced Epoch loss:1.3878998, train acc:25.1396, val loss:1.3865452, val acc:25.1250 in 0h 0m 47s\n",
      "epoch [17/20] Forced Epoch loss:1.3878417, train acc:25.2771, val loss:1.3865496, val acc:25.0917 in 0h 3m 46s\n",
      "epoch [18/20] Unforced Epoch loss:1.3878969, train acc:24.9500, val loss:1.3865279, val acc:25.0917 in 0h 0m 47s\n",
      "epoch [19/20] Forced Epoch loss:1.3878666, train acc:25.0073, val loss:1.3865313, val acc:25.1250 in 0h 3m 46s\n",
      "epoch [20/20] Unforced Epoch loss:1.3879346, train acc:25.0115, val loss:1.3864358, val acc:25.1250 in 0h 0m 47s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "top_n = 5\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    ##################\n",
    "    #print('At start')\n",
    "    #time.sleep(10)\n",
    "    if epoch%2 == 1:\n",
    "        mode = 'Forced Epoch'\n",
    "        \n",
    "        for layer in unique_layers:\n",
    "            weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "            biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "            if 'bn' in layer:\n",
    "                running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "                running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "                W = [weights, biases, running_mean, running_var]\n",
    "            elif 'fc' in layer:\n",
    "                biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "                W = [weights.T, biases]\n",
    "            else:\n",
    "                W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "            k_model.get_layer(layer).set_weights(W)\n",
    "        \n",
    "        ############\n",
    "        #print('After model load')\n",
    "        #time.sleep(10)\n",
    "        for ib,sample in enumerate(train_loader):\n",
    "            \n",
    "            data_input = sample['matrix'][:,None,:,:].numpy()\n",
    "            data_output = sample['class'][:,0].numpy()\n",
    "\n",
    "            for j in range(BATCHSIZE):\n",
    "                #index = train_indices[BATCHSIZE*ib+j]\n",
    "                #sample = dset[index]\n",
    "                try:\n",
    "                    data = data_input[j]\n",
    "                except IndexError as error:\n",
    "                    break\n",
    "                \n",
    "                data = data.reshape((1, -1, 300,1))    \n",
    "                analysis = np.zeros(data.shape[1])\n",
    "                \n",
    "                a = np.squeeze(analyzer.analyze(data,neuron_selection=data_output[j]))\n",
    "                a = np.sum(a, axis=1)\n",
    "                \n",
    "                order = np.argsort(a)[::-1]\n",
    "                for k in order[top_n:]:\n",
    "                    data_input[j,:,k,:] = np.zeros((1,1,300)) \n",
    "            \n",
    "            data_input = torch.as_tensor(data_input)\n",
    "            data_output = torch.as_tensor(data_output)\n",
    "            \n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= (train_points)\n",
    "        tacc = tacc*100.0/ (train_points)\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "        \n",
    "        \n",
    "    if epoch%2 == 0:    \n",
    "        mode = 'Unforced Epoch'\n",
    "        for ib,sample in enumerate(train_loader):\n",
    "\n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= train_points \n",
    "        tacc = tacc*100.0/ train_points\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'fasttext/feedback_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model.state_dict(), 'fasttext/feedback_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(np.array(loss_values_train), 'b')\n",
    "plt.plot(np.array(loss_values_val), 'r')\n",
    "plt.legend(['Train','Val'])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 25.00%\n"
     ]
    }
   ],
   "source": [
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 - World\n",
      "1 - Sports\n",
      "2 - Business\n",
      "3 - Sci/Tech\n",
      "\n",
      "54230\n",
      "Printing Train + Val Number of Documents Found\n",
      "120000\n",
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n",
      "---Printing Parameters Finished!---\n",
      "Test Accuracy : 91.12%\n",
      "channels_last\n",
      "['conv1' 'fc1' 'fc2' 'fc3']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, 300, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, 1, 1024)     922624    \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_2 (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,193,380\n",
      "Trainable params: 1,193,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LEARNINGRATE = 5e-3\n",
    "GAMMA = 0.8\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "NUMEPOCHS = 20\n",
    "\n",
    "\n",
    "dset = CustomDataset.get_dataset('data/train.csv')\n",
    "tset = CustomDataset.get_dataset('data/test.csv')\n",
    "\n",
    "print('''\n",
    "0 - World\n",
    "1 - Sports\n",
    "2 - Business\n",
    "3 - Sci/Tech\n",
    "''')\n",
    "\n",
    "### TRAIN VAL SPLIT\n",
    "\n",
    "NUM_DATA_POINTS = len(dset)\n",
    "\n",
    "indices = list(range(NUM_DATA_POINTS))\n",
    "split = int(np.floor(0.2 * NUM_DATA_POINTS))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(indices[0])\n",
    "\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_points = len(train_indices)\n",
    "val_points = len(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE, \n",
    "                                           sampler=train_sampler, num_workers=4)\n",
    "validation_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE,\n",
    "                                                sampler=valid_sampler, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(tset, batch_size = BATCHSIZE,\n",
    "                                                num_workers=4)\n",
    "\n",
    "print(\"Printing Train + Val Number of Documents Found\")\n",
    "print(NUM_DATA_POINTS)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/weights_2/Model_quicksave5.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model.eval()\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        #print(param.shape)\n",
    "print('---Printing Parameters Finished!---')\n",
    "\n",
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from keras.layers import Conv2D, Input, Dense, MaxPool2D, Flatten, Lambda, GlobalMaxPool2D, Dropout\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import innvestigate\n",
    "import innvestigate.applications\n",
    "import innvestigate.applications.mnist\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.utils.tests.networks import base as network_base\n",
    "\n",
    "print(K.image_data_format())\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    inp = Input((None,300,1))\n",
    "    x = Conv2D(1024,(3,300),activation='relu', name='conv1')(inp)\n",
    "    x = GlobalMaxPool2D('channels_last')(x)\n",
    "    x = Dense(256,name='fc1',activation='relu')(x)\n",
    "    z = Dropout(0.25)(x)\n",
    "    ou = Dense(32,name='fc2',activation='relu')(z)\n",
    "    ou = Dropout(0.3)(ou)\n",
    "    out = Dense(4,name='fc3')(ou)\n",
    "    outz = Dropout(0.2)(out)\n",
    "    k_model = Model(inp, outz)\n",
    "\n",
    "\n",
    "trained_weights = model.state_dict()\n",
    "\n",
    "pytorch_layers = [] # get ptroch layers names and suffixes\n",
    "for x, l in zip(trained_weights, k_model.layers):\n",
    "    pytorch_layers.append(x[:x.find('.')])\n",
    "\n",
    "unique_layers = np.unique(pytorch_layers)\n",
    "print(unique_layers)\n",
    "\n",
    "\n",
    "for layer in unique_layers:\n",
    "    weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "    biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "    if 'bn' in layer:\n",
    "        running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "        running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "        W = [weights, biases, running_mean, running_var]\n",
    "    elif 'fc' in layer:\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        W = [weights.T, biases]\n",
    "    else:\n",
    "        W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "    k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "k_model.summary()\n",
    "\n",
    "method = (\"lrp.z\",{},\"LRP-Z\")\n",
    "         \n",
    "analyzer = innvestigate.create_analyzer(method[0], k_model,neuron_selection_mode=\"index\",**method[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  1024\n",
      "epoch [1/10] Forced Epoch loss:0.1198138, train acc:93.5781, val loss:0.3919879, val acc:90.2292 in 0h 3m 48s\n",
      "epoch [2/10] Forced Epoch loss:0.1006320, train acc:94.1323, val loss:0.4347302, val acc:87.2583 in 0h 3m 47s\n",
      "epoch [3/10] Forced Epoch loss:0.1051836, train acc:94.0396, val loss:0.5511228, val acc:84.2917 in 0h 3m 48s\n",
      "epoch [4/10] Forced Epoch loss:0.1029531, train acc:94.0396, val loss:0.5325821, val acc:84.8917 in 0h 3m 47s\n",
      "epoch [5/10] Forced Epoch loss:0.1069773, train acc:93.9542, val loss:0.4758463, val acc:84.9125 in 0h 3m 47s\n",
      "epoch [6/10] Forced Epoch loss:0.1016999, train acc:94.1417, val loss:0.5674221, val acc:83.7458 in 0h 3m 47s\n",
      "epoch [7/10] Forced Epoch loss:0.0993273, train acc:94.2562, val loss:0.4914397, val acc:86.1542 in 0h 3m 48s\n",
      "epoch [8/10] Forced Epoch loss:0.0965952, train acc:94.3833, val loss:0.7383861, val acc:81.4375 in 0h 3m 48s\n",
      "epoch [9/10] Forced Epoch loss:0.0969612, train acc:94.2917, val loss:0.6404241, val acc:83.7292 in 0h 3m 47s\n",
      "epoch [10/10] Forced Epoch loss:0.0913545, train acc:94.4146, val loss:0.5376525, val acc:86.0875 in 0h 3m 48s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "NUMEPOCHS = 10\n",
    "top_n = 7\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    ##################\n",
    "    #print('At start')\n",
    "    #time.sleep(10)\n",
    "    mode = 'Forced Epoch'\n",
    "\n",
    "    for layer in unique_layers:\n",
    "        weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        if 'bn' in layer:\n",
    "            running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "            running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "            W = [weights, biases, running_mean, running_var]\n",
    "        elif 'fc' in layer:\n",
    "            biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "            W = [weights.T, biases]\n",
    "        else:\n",
    "            W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "        k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "    ############\n",
    "    #print('After model load')\n",
    "    #time.sleep(10)\n",
    "    for ib,sample in enumerate(train_loader):\n",
    "\n",
    "        data_input = sample['matrix'][:,None,:,:].numpy()\n",
    "        data_output = sample['class'][:,0].numpy()\n",
    "\n",
    "        for j in range(BATCHSIZE):\n",
    "            #index = train_indices[BATCHSIZE*ib+j]\n",
    "            #sample = dset[index]\n",
    "            try:\n",
    "                data = data_input[j]\n",
    "            except IndexError as error:\n",
    "                break\n",
    "\n",
    "            data = data.reshape((1, -1, 300,1))    \n",
    "            analysis = np.zeros(data.shape[1])\n",
    "\n",
    "            a = np.squeeze(analyzer.analyze(data,neuron_selection=data_output[j]))\n",
    "            a = np.sum(a, axis=1)\n",
    "\n",
    "            order = np.argsort(a)[::-1]\n",
    "            for k in order[top_n:]:\n",
    "                data_input[j,:,k,:] = np.zeros((1,1,300)) \n",
    "\n",
    "        data_input = torch.as_tensor(data_input)\n",
    "        data_output = torch.as_tensor(data_output)\n",
    "\n",
    "        data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "        data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "        output = model(data_input) \n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        loss = criterion(output, data_output)\n",
    "        runloss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        runloss += loss.item() * data_input.size(0)\n",
    "        tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "    runloss /= (train_points)\n",
    "    tacc = tacc*100.0/ (train_points)\n",
    "\n",
    "    loss_values_train.append(runloss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'fasttext/feedback-v2_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model.state_dict(), 'fasttext/feedback-v2_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(np.array(loss_values_train), 'b')\n",
    "plt.plot(np.array(loss_values_val), 'r')\n",
    "plt.legend(['Train','Val'])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Test Accuracy : 88.54%\n",
      "Test Accuracy : 85.68%\n",
      "Test Accuracy : 83.63%\n",
      "Test Accuracy : 83.71%\n",
      "Test Accuracy : 83.99%\n",
      "Test Accuracy : 82.89%\n",
      "Test Accuracy : 84.57%\n",
      "Test Accuracy : 80.29%\n",
      "Test Accuracy : 82.41%\n",
      "Test Accuracy : 84.70%\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "for i in range(10):\n",
    "    FILE = 'fasttext/feedback-v2_POS/Model_quicksave'+str(i+1)+'.pt'\n",
    "\n",
    "    model.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "    model.eval()\n",
    "\n",
    "    corr = 0.0\n",
    "    with torch.no_grad():\n",
    "      for ib,sample in enumerate(test_loader):\n",
    "\n",
    "        data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "        data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "        data_input = data_input.to(device, dtype=torch.float)\n",
    "        data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "        output = model(data_input)\n",
    "        _, preds = torch.max(output,dim=1)\n",
    "        corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "    print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 - World\n",
      "1 - Sports\n",
      "2 - Business\n",
      "3 - Sci/Tech\n",
      "\n",
      "89438\n",
      "Printing Train + Val Number of Documents Found\n",
      "120000\n",
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n",
      "---Printing Parameters Finished!---\n",
      "Test Accuracy : 91.12%\n",
      "channels_last\n",
      "['conv1' 'fc1' 'fc2' 'fc3']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, None, 300, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, 1, 1024)     922624    \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_3 (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,193,380\n",
      "Trainable params: 1,193,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LEARNINGRATE = 3e-5\n",
    "GAMMA = 0.8\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "NUMEPOCHS = 5\n",
    "\n",
    "\n",
    "dset = CustomDataset.get_dataset('data/train.csv')\n",
    "tset = CustomDataset.get_dataset('data/test.csv')\n",
    "\n",
    "print('''\n",
    "0 - World\n",
    "1 - Sports\n",
    "2 - Business\n",
    "3 - Sci/Tech\n",
    "''')\n",
    "\n",
    "### TRAIN VAL SPLIT\n",
    "\n",
    "NUM_DATA_POINTS = len(dset)\n",
    "\n",
    "indices = list(range(NUM_DATA_POINTS))\n",
    "split = int(np.floor(0.2 * NUM_DATA_POINTS))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(indices[0])\n",
    "\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_points = len(train_indices)\n",
    "val_points = len(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE, \n",
    "                                           sampler=train_sampler, num_workers=4)\n",
    "validation_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE,\n",
    "                                                sampler=valid_sampler, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(tset, batch_size = BATCHSIZE,\n",
    "                                                num_workers=4)\n",
    "\n",
    "print(\"Printing Train + Val Number of Documents Found\")\n",
    "print(NUM_DATA_POINTS)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/weights_2/Model_quicksave5.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model.eval()\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        #print(param.shape)\n",
    "print('---Printing Parameters Finished!---')\n",
    "\n",
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from keras.layers import Conv2D, Input, Dense, MaxPool2D, Flatten, Lambda, GlobalMaxPool2D, Dropout\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import innvestigate\n",
    "import innvestigate.applications\n",
    "import innvestigate.applications.mnist\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.utils.tests.networks import base as network_base\n",
    "\n",
    "print(K.image_data_format())\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    inp = Input((None,300,1))\n",
    "    x = Conv2D(1024,(3,300),activation='relu', name='conv1')(inp)\n",
    "    x = GlobalMaxPool2D('channels_last')(x)\n",
    "    x = Dense(256,name='fc1',activation='relu')(x)\n",
    "    z = Dropout(0.25)(x)\n",
    "    ou = Dense(32,name='fc2',activation='relu')(z)\n",
    "    ou = Dropout(0.3)(ou)\n",
    "    out = Dense(4,name='fc3')(ou)\n",
    "    outz = Dropout(0.2)(out)\n",
    "    k_model = Model(inp, outz)\n",
    "\n",
    "\n",
    "trained_weights = model.state_dict()\n",
    "\n",
    "pytorch_layers = [] # get ptroch layers names and suffixes\n",
    "for x, l in zip(trained_weights, k_model.layers):\n",
    "    pytorch_layers.append(x[:x.find('.')])\n",
    "\n",
    "unique_layers = np.unique(pytorch_layers)\n",
    "print(unique_layers)\n",
    "\n",
    "\n",
    "for layer in unique_layers:\n",
    "    weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "    biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "    if 'bn' in layer:\n",
    "        running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "        running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "        W = [weights, biases, running_mean, running_var]\n",
    "    elif 'fc' in layer:\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        W = [weights.T, biases]\n",
    "    else:\n",
    "        W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "    k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "k_model.summary()\n",
    "\n",
    "method = (\"lrp.z\",{},\"LRP-Z\")\n",
    "         \n",
    "analyzer = innvestigate.create_analyzer(method[0], k_model,neuron_selection_mode=\"index\",**method[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  1024\n",
      "epoch [1/5] Forced Epoch loss:0.1361508, train acc:93.3156, val loss:0.1750172, val acc:94.0792 in 0h 3m 49s\n",
      "epoch [2/5] Forced Epoch loss:0.1209859, train acc:93.7323, val loss:0.1782828, val acc:94.1792 in 0h 3m 48s\n",
      "epoch [3/5] Forced Epoch loss:0.1131830, train acc:93.9000, val loss:0.1894303, val acc:94.0625 in 0h 3m 48s\n",
      "epoch [4/5] Forced Epoch loss:0.1086684, train acc:93.9979, val loss:0.1992264, val acc:94.0417 in 0h 3m 48s\n",
      "epoch [5/5] Forced Epoch loss:0.1054403, train acc:94.0062, val loss:0.2088471, val acc:93.9958 in 0h 3m 49s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "NUMEPOCHS = 5\n",
    "top_n = 6\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    ##################\n",
    "    #print('At start')\n",
    "    #time.sleep(10)\n",
    "    mode = 'Forced Epoch'\n",
    "\n",
    "    for layer in unique_layers:\n",
    "        weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        if 'bn' in layer:\n",
    "            running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "            running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "            W = [weights, biases, running_mean, running_var]\n",
    "        elif 'fc' in layer:\n",
    "            biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "            W = [weights.T, biases]\n",
    "        else:\n",
    "            W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "        k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "    ############\n",
    "    #print('After model load')\n",
    "    #time.sleep(10)\n",
    "    for ib,sample in enumerate(train_loader):\n",
    "\n",
    "        data_input = sample['matrix'][:,None,:,:].numpy()\n",
    "        data_output = sample['class'][:,0].numpy()\n",
    "\n",
    "        for j in range(BATCHSIZE):\n",
    "            #index = train_indices[BATCHSIZE*ib+j]\n",
    "            #sample = dset[index]\n",
    "            try:\n",
    "                data = data_input[j]\n",
    "            except IndexError as error:\n",
    "                break\n",
    "\n",
    "            data = data.reshape((1, -1, 300,1))    \n",
    "            analysis = np.zeros(data.shape[1])\n",
    "\n",
    "            a = np.squeeze(analyzer.analyze(data,neuron_selection=data_output[j]))\n",
    "            a = np.sum(a, axis=1)\n",
    "\n",
    "            order = np.argsort(a)[::-1]\n",
    "            for k in order[top_n:]:\n",
    "                data_input[j,:,k,:] = np.zeros((1,1,300)) \n",
    "\n",
    "        data_input = torch.as_tensor(data_input)\n",
    "        data_output = torch.as_tensor(data_output)\n",
    "\n",
    "        data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "        data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "        output = model(data_input) \n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        loss = criterion(output, data_output)\n",
    "        runloss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        runloss += loss.item() * data_input.size(0)\n",
    "        tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "    runloss /= (train_points)\n",
    "    tacc = tacc*100.0/ (train_points)\n",
    "\n",
    "    loss_values_train.append(runloss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'fasttext/feedback-v3_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model.state_dict(), 'fasttext/feedback-v3_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Test Accuracy : 91.68%\n",
      "Test Accuracy : 91.82%\n",
      "Test Accuracy : 91.67%\n",
      "Test Accuracy : 91.45%\n",
      "Test Accuracy : 91.39%\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "for i in range(5):\n",
    "    FILE = 'fasttext/feedback-v3_POS/Model_quicksave'+str(i+1)+'.pt'\n",
    "\n",
    "    model.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "    model.eval()\n",
    "\n",
    "    corr = 0.0\n",
    "    with torch.no_grad():\n",
    "      for ib,sample in enumerate(test_loader):\n",
    "\n",
    "        data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "        data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "        data_input = data_input.to(device, dtype=torch.float)\n",
    "        data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "        output = model(data_input)\n",
    "        _, preds = torch.max(output,dim=1)\n",
    "        corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "    print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_ptorch",
   "language": "python",
   "name": "gpu_ptorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
