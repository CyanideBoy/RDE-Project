{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /nfs4/ushashi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from model import ConvNet_Shallow_Single as ConvNet_SS\n",
    "from model import ConvNet \n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "import fasttext.CustomDataset as CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nfs4/ushashi/anaconda3/envs/gpu_ptorch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 - World\n",
      "1 - Sports\n",
      "2 - Business\n",
      "3 - Sci/Tech\n",
      "\n",
      "23848\n",
      "Printing Train + Val Number of Documents Found\n",
      "120000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "        \n",
    "\n",
    "LEARNINGRATE = 9e-2\n",
    "GAMMA = 0.94\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "NUMEPOCHS = 20\n",
    "\n",
    "\n",
    "dset = CustomDataset.get_dataset('data/train.csv')\n",
    "tset = CustomDataset.get_dataset('data/test.csv')\n",
    "\n",
    "print('''\n",
    "0 - World\n",
    "1 - Sports\n",
    "2 - Business\n",
    "3 - Sci/Tech\n",
    "''')\n",
    "\n",
    "### TRAIN VAL SPLIT\n",
    "\n",
    "NUM_DATA_POINTS = len(dset)\n",
    "\n",
    "indices = list(range(NUM_DATA_POINTS))\n",
    "split = int(np.floor(0.2 * NUM_DATA_POINTS))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(indices[0])\n",
    "\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_points = len(train_indices)\n",
    "val_points = len(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE, \n",
    "                                           sampler=train_sampler, num_workers=4)\n",
    "validation_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE,\n",
    "                                                sampler=valid_sampler, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(tset, batch_size = BATCHSIZE,\n",
    "                                                num_workers=4)\n",
    "\n",
    "print(\"Printing Train + Val Number of Documents Found\")\n",
    "print(NUM_DATA_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n",
      "---Printing Parameters Finished!---\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/weights_2/Model_quicksave5.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model.eval()\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        #print(param.shape)\n",
    "print('---Printing Parameters Finished!---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 91.12%\n"
     ]
    }
   ],
   "source": [
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "['conv1' 'fc1' 'fc2' 'fc3']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 300, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, 1, 1024)     922624    \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,193,380\n",
      "Trainable params: 1,193,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from keras.layers import Conv2D, Input, Dense, MaxPool2D, Flatten, Lambda, GlobalMaxPool2D, Dropout\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import innvestigate\n",
    "import innvestigate.applications\n",
    "import innvestigate.applications.mnist\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.utils.tests.networks import base as network_base\n",
    "\n",
    "print(K.image_data_format())\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    inp = Input((None,300,1))\n",
    "    x = Conv2D(1024,(3,300),activation='relu', name='conv1')(inp)\n",
    "    x = GlobalMaxPool2D('channels_last')(x)\n",
    "    x = Dense(256,name='fc1',activation='relu')(x)\n",
    "    z = Dropout(0.25)(x)\n",
    "    ou = Dense(32,name='fc2',activation='relu')(z)\n",
    "    ou = Dropout(0.3)(ou)\n",
    "    out = Dense(4,name='fc3')(ou)\n",
    "    outz = Dropout(0.2)(out)\n",
    "    k_model = Model(inp, outz)\n",
    "\n",
    "\n",
    "trained_weights = model.state_dict()\n",
    "\n",
    "pytorch_layers = [] # get ptroch layers names and suffixes\n",
    "for x, l in zip(trained_weights, k_model.layers):\n",
    "    pytorch_layers.append(x[:x.find('.')])\n",
    "\n",
    "unique_layers = np.unique(pytorch_layers)\n",
    "print(unique_layers)\n",
    "\n",
    "\n",
    "for layer in unique_layers:\n",
    "    weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "    biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "    if 'bn' in layer:\n",
    "        running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "        running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "        W = [weights, biases, running_mean, running_var]\n",
    "    elif 'fc' in layer:\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        W = [weights.T, biases]\n",
    "    else:\n",
    "        W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "    k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "k_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(train_points):\\n \\n    index = train_indices[i]\\n    x = dset[index]['matrix']\\n    x = x.reshape((1, -1, 300,1)).numpy()    \\n    analyzis[i] = np.zeros(x.shape[1])\\n    \\n    a = np.squeeze(analyzer.analyze(x))\\n    a = np.sum(a, axis=1)\\n    analyzis[i] = a   \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = (\"lrp.z\",{},\"LRP-Z\")\n",
    "         \n",
    "analyzer = innvestigate.create_analyzer(method[0], k_model,neuron_selection_mode=\"index\",**method[1]) #neuron_selection_mode=\"index\",  \n",
    "\n",
    "'''\n",
    "for i in range(train_points):\n",
    " \n",
    "    index = train_indices[i]\n",
    "    x = dset[index]['matrix']\n",
    "    x = x.reshape((1, -1, 300,1)).numpy()    \n",
    "    analyzis[i] = np.zeros(x.shape[1])\n",
    "    \n",
    "    a = np.squeeze(analyzer.analyze(x))\n",
    "    a = np.sum(a, axis=1)\n",
    "    analyzis[i] = a   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  1024\n",
      "epoch [1/20] Forced Epoch loss:0.1954318, train acc:91.9344, val loss:0.6349125, val acc:80.3250 in 0h 3m 59s\n",
      "epoch [2/20] Unforced Epoch loss:1.5850650, train acc:26.2271, val loss:1.3866769, val acc:24.8667 in 0h 0m 43s\n",
      "epoch [3/20] Forced Epoch loss:1.3886599, train acc:24.7396, val loss:1.3865986, val acc:24.9167 in 0h 3m 58s\n",
      "epoch [4/20] Unforced Epoch loss:1.3880080, train acc:25.0344, val loss:1.3863088, val acc:25.0917 in 0h 0m 44s\n",
      "epoch [5/20] Forced Epoch loss:1.3886124, train acc:25.0542, val loss:1.3863903, val acc:25.1250 in 0h 4m 0s\n",
      "epoch [6/20] Unforced Epoch loss:1.3897905, train acc:24.8167, val loss:1.3864269, val acc:25.1250 in 0h 0m 44s\n",
      "epoch [7/20] Forced Epoch loss:1.3878485, train acc:24.9396, val loss:1.3863330, val acc:25.0917 in 0h 3m 59s\n",
      "epoch [8/20] Unforced Epoch loss:1.3911532, train acc:25.0240, val loss:1.3868168, val acc:25.1250 in 0h 0m 44s\n",
      "epoch [9/20] Forced Epoch loss:1.3879875, train acc:25.1177, val loss:1.3865719, val acc:24.9167 in 0h 3m 58s\n",
      "epoch [10/20] Unforced Epoch loss:1.3881547, train acc:25.0281, val loss:1.3865415, val acc:24.9167 in 0h 0m 44s\n",
      "epoch [11/20] Forced Epoch loss:1.3881257, train acc:24.9208, val loss:1.3865829, val acc:24.9167 in 0h 4m 4s\n",
      "epoch [12/20] Unforced Epoch loss:1.3880869, train acc:24.8313, val loss:1.3864509, val acc:25.0917 in 0h 0m 44s\n",
      "epoch [13/20] Forced Epoch loss:1.3879888, train acc:24.9990, val loss:1.3864355, val acc:24.9167 in 0h 4m 5s\n",
      "epoch [14/20] Unforced Epoch loss:1.3880091, train acc:25.0052, val loss:1.3869506, val acc:24.8667 in 0h 0m 43s\n",
      "epoch [15/20] Forced Epoch loss:1.3880890, train acc:24.9740, val loss:1.3864834, val acc:24.8667 in 0h 4m 4s\n",
      "epoch [16/20] Unforced Epoch loss:1.3878743, train acc:25.1458, val loss:1.3862984, val acc:25.0917 in 0h 0m 43s\n",
      "epoch [17/20] Forced Epoch loss:1.3879280, train acc:24.7979, val loss:1.3863276, val acc:25.1250 in 0h 3m 58s\n",
      "epoch [18/20] Unforced Epoch loss:1.3879071, train acc:24.7323, val loss:1.3863111, val acc:25.0917 in 0h 0m 48s\n",
      "epoch [19/20] Forced Epoch loss:1.3880422, train acc:24.9667, val loss:1.3866423, val acc:24.9167 in 0h 3m 57s\n",
      "epoch [20/20] Unforced Epoch loss:1.3880499, train acc:25.0490, val loss:1.3867244, val acc:24.9167 in 0h 0m 50s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "top_n = 5\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    ##################\n",
    "    #print('At start')\n",
    "    #time.sleep(10)\n",
    "    if epoch%2 == 1:\n",
    "        mode = 'Forced Epoch'\n",
    "        \n",
    "        for layer in unique_layers:\n",
    "            weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "            biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "            if 'bn' in layer:\n",
    "                running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "                running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "                W = [weights, biases, running_mean, running_var]\n",
    "            elif 'fc' in layer:\n",
    "                biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "                W = [weights.T, biases]\n",
    "            else:\n",
    "                W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "            k_model.get_layer(layer).set_weights(W)\n",
    "        \n",
    "        ############\n",
    "        #print('After model load')\n",
    "        #time.sleep(10)\n",
    "        for ib,sample in enumerate(train_loader):\n",
    "            \n",
    "            data_input = sample['matrix'][:,None,:,:].numpy()\n",
    "            data_output = sample['class'][:,0].numpy()\n",
    "\n",
    "            for j in range(BATCHSIZE):\n",
    "                #index = train_indices[BATCHSIZE*ib+j]\n",
    "                #sample = dset[index]\n",
    "                try:\n",
    "                    data = data_input[j]\n",
    "                except IndexError as error:\n",
    "                    break\n",
    "                \n",
    "                data = data.reshape((1, -1, 300,1))    \n",
    "                analysis = np.zeros(data.shape[1])\n",
    "                \n",
    "                a = np.squeeze(analyzer.analyze(data,neuron_selection=data_output[j]))\n",
    "                a = np.sum(a, axis=1)\n",
    "                \n",
    "                order = np.argsort(a)[::-1]\n",
    "                for k in order[top_n:]:\n",
    "                    data_input[j,:,k,:] = np.zeros((1,1,300)) \n",
    "            \n",
    "            data_input = torch.as_tensor(data_input)\n",
    "            data_output = torch.as_tensor(data_output)\n",
    "            \n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= (train_points)\n",
    "        tacc = tacc*100.0/ (train_points)\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "        \n",
    "        \n",
    "    if epoch%2 == 0:    \n",
    "        mode = 'Unforced Epoch'\n",
    "        for ib,sample in enumerate(train_loader):\n",
    "\n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "            data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "            output = model(data_input) \n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            loss = criterion(output, data_output)\n",
    "            runloss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runloss += loss.item() * data_input.size(0)\n",
    "            tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "        runloss /= train_points \n",
    "        tacc = tacc*100.0/ train_points\n",
    "\n",
    "        loss_values_train.append(runloss)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'fasttext/feedback_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model.state_dict(), 'fasttext/feedback_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGaCAYAAADU7OPrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3xU9Z3/8ffJjRDuIoRLSAZCw8UgQS4qIuqagqbougUprajUVOni1t3y6NLLD5Fi20Vqs7UUK1rBdrWKQmu3LJItu4pieawixZLSCmUSk4hImCFAQhKSzPn9MZmYkJlkJjlnZjLzej4ePCZz5jszn29OJnnzOTfDNE1TAAAAUSIh0gUAAAC0RTgBAABRhXACAACiCuEEAABEFcIJAACIKoQTAAAQVZIiXUBP9enTR8OGDbP8dRsaGtSnTx/LXzdaxdN8mWvsiqf5MtfYFS/zraqqUkNDg9/Hen04GTZsmCorKy1/3eLiYs2fP9/y141W8TRf5hq74mm+zDV2xct8MzIyAj7GZh0AABBVCCcAACCqEE4AAEBU6fX7nAAAEI08Ho+6e/m65uZmi6sJP8MwlJDQvR4I4QQAAAtdvHhR5eXlamxs7Nbzhw0bpqNHj1pcVWQkJycrMzNTKSkpIT2PcAIAgIXKy8s1YMAADR06VIZhhPz8c+fOaeDAgTZUFl6macrlcqm8vFzjx48P6bmEEwAALOLxeNTY2KihQ4cqKal7f2ITEhKUmJhocWWRMXToULndbnk8npA28bBDLAAAFvHtY9Kdjkks8n0fQt33xvZw8tBDD8nhcMgwDJWUlAQct3fvXs2cOVNXXHGFJk6cqP3799tdGgAAiEK2h5NFixZp3759ysrKCjjmxIkTuvfee/XLX/5Sf/7zn3Xo0CFNmjTJ7tIAAIhpeXl5ysvL0+TJk5WUlNR6/wtf+ELIrzV//nyVlZVZX6Qftu9zMnfu3C7HPPnkk1q6dGlrIElNTVVqaqrdpQEAENMOHTokSSorK9OMGTNa7/vT1NTU6X4yxcXFltcXiGF29yDsEDkcDu3cuVO5ubkdHvv85z+vsWPH6v3339fp06d1/fXX67HHHlNaWlqHsUVFRSoqKmq9X11drR07dlheb319fVwFpHiaL3ONXfE0X+YavYYNG6axY8cqISFBS5akqazMvo0UDodHL710octxH374oW666SY5nc7WZW+88YYeeeQRzZo1S4cOHdLXvvY1XbhwQU8//XTrYdCPPPKI8vPzJUmTJ0/Wq6++qpycHN1yyy265ppr9H//9386ceKE5s2bpx/+8Icd3tfj8ai0tFRVVVUdHissLAx4bbyoOFqnsbFRb7zxhvbs2aMBAwbovvvu09q1a7Vhw4YOY1euXKmVK1e23s/IyLDlAknxcuEln3iaL3ONXfE0X+YanZqbm3X06FENHDhQiYmJSk6WQj0PmcfTrISE4I7WSU5O1KBBg7ocN3DgQBmG0W5sv379dPjwYf3sZz/TtddeK0k6ffq0HnjgARmGIafTqTlz5qiiokKJiYkyDEMDBgzQoEGDlJiYqI8//lhvvfWWGhoaNHHiRN1///2aOXNmu/dtbm5W3759lZ+fH9IRSFERTrKysjRt2jQNGTJEkrRkyRK/wQQAgN7kP/8z9OecPVsTVOCwwqRJk1qDiSQ5nU7ddddd+uijj5SUlKTTp0+roqJCDoejw3OXLFmixMREpaWlaerUqTp+/HiHcNJdUXEo8Ze+9CW9/vrramhokCTt3r1bU6dOjXBV9vnud6W5c6VunjwQAABL9O/fv939xYsX62tf+5pKSkp06NAhpaamqr6+3u9z225qS0xMVFNTk2V12R5OHnzwQWVkZKiyslL5+fmtZ4krKCjQgQMHJEmzZ8/Wbbfdpry8PE2ZMkVVVVVat26d3aVFzJ490ltvSb/4RaQrAQDgU9XV1a1dkueee07nz5+PSB22b9bZtGmTNm3a1GH5rl272t1ftWqVVq1aZXc5UcHt9t4++qh0zz1SiJccAADAFj/+8Y+1YMECjRkzRrNnz9bo0aMjUkdU7HMSb1wu7215ufTss9I//mNk6wEAxDaHw6HTp0+3W5afn996JI7PsmXLtGzZstb7jz32WOvXbY+s2bdvX7vnvfrqqxZWGyX7nMQT0/R2Tm66SRo+XPr+96UAm/MAAIhLhJMwq6nx7gibmSl961vSRx9JTz8d6aoAAIgehJMw8+1vctll0le/Ko0cKf3bv0kXuj6HDgAAcYFwEma+cDJ0qNS3r/Sd70gnT0o/+1lk6wIAIFoQTsLMtzPsZZd5b7/yFSkjQ3rsMe8mHwAA4h3hJMzadk4kKTVVWr1aqqqS/BxxDQBA3CGchNmlnRNJ+vKXpawsacMG6dy5yNQFAEC0IJyE2aWdE8l7EraHH/Y+9pOfRKYuAEBsuvXWW/XTn/60w/KpU6fqN7/5TcDnLVu2zO/zwoFwEmb+OieS90yx2dnSj34kVVeHvy4AQGwqLCzU1q1b2y07cOCATp48qQULFkSoqs5xhtgwa3socVvJydKaNdK990r//u/eiwMCAHq522+Xjh8P6Sn9PR4pIcjeQXZ2l5c+vv3227VixQq9//77rRfV3bJli+655x799a9/1YoVK1RbW6v6+nrdfffd+va3vx1SvXagcxJmLpc3iFxyIUhJ0pe+JE2Y4A0nvg4LAAA9kZKSoqVLl7Z2T+rr6/XSSy/pvvvuk8Ph0J49e3Tw4EG99957evnll1svyhtJdE7CzO32dk0Mo+NjSUnSI494Q8qPfiT94Afhrw8AYKEuuhr+1Jw9q0GDBllaRmFhoW688UZt2LBBv/71rzVp0iRNmjRJp06d0ooVK3To0CElJCSooqJChw4d0owZMyx9/1DROQkzt7v9zrCXWrxYuuIK746xVVXhqwsAELuuuOIKZWdn63e/+522bNmiwsJCSdJ3vvMdpaen649//KPef/993XjjjaqPggu+EU7CzOXquL9JW4mJ0tq1Um2t99BiAACsUFhYqB/84Ad69913tXjxYknSmTNnlJGRoaSkJH3wwQf6/e9/H+EqvQgnYeS7InFnnRNJ+vznpalTvSdlO3kyPLUBAGLbkiVL9MEHH2jRokXq37Lj4+rVq/Xzn/9cM2fO1OrVq/V3f/d3Ea7Si31OwujcOam5ufPOieTdSfu735XuuENav1768Y/DUx8AIHYNGDBANZdcJ2XatGkqKSnxO/65554LQ1X+0TkJI38nYAvk9tul6dOlp56SKivtrQsAgGhCOAmjQCdg88cwpHXrpIYG6d/+zd66AACIJoSTMAp0ArZAbr1VuuYa6ZlnpPJy++oCAFjDaDlPhGmaEa4kOvi+D4a/82d0gn1OwsjXOQlms470afdk3jzpe9+Tnn7avtoAAD2XkJCg5ORkuVwuDR06NOQ/ypLk8XjU3NxsQ3XhZZqmXC6XkpOTlRDsGW9bEE7CKNTOiSTl50tz5khbt0rf+pY0bpw9tQEArJGZmany8nK5fb/0Q1RXV6e+fftaXFVkJCcnKzMzM+TnEU7CKJQdYn0MQ3r0Uemmm7y3l1y7CQAQZVJSUjR+/Hh5PJ5ubd7Zs2eP8vPzbagsvAzDCLlj4kM4CaNQdoht68YbveHkl7+UvvMd6TOfsbw0AIDFuvuHWZISExMtrKT3YYfYMOpO58Rn3TrJ4+FqxQCA2Ec4CSOXS+rTR+rOpsQ5c7w7xv7qV9Jf/mJ9bQAARAvCSRh1dkXiYKxb5z0F/tq1lpYFAEBUIZyEkcvVvU06PldfLX3uc9LLL0uHD1tXFwAA0YRwEka+zklPrFvnvX3kkZ7XAwBANCKchInHI50507POiSRddZX3goC/+Y108KA1tQEAEE0IJ2Fy9qw3oPS0cyJ9esQO3RMAQCwinIRJTw4jvtSVV0p33int3Cm9807PXw8AgGhCOAmT7p6ALZC1a71H/dA9AQDEGsJJmFjZOZGkyZOlL35R2r1b+sMfrHlNAACiAeEkTKzunEjSmjVSQoL3FgCAWEE4CZPuXJG4KxMmSHffLf3P/0h791r3ugAARBLhJEx8nROrNuv4PPywlJjo7Z504+KXAABEHcJJmNjROZGk7Gzpy1+W3nzT20EBAKC3sz2cPPTQQ3I4HDIMQyUlJZ2OraqqUnp6uhYtWmR3WWFnVziRpNWrpeRkuicAgNhgezhZtGiR9u3bp6ysrC7HrlixQgUFBXaXFBEul/dqxN25InFXsrKkr3xF2r/fe/QOAAC9me3hZO7cucrIyOhy3AsvvKD09HTdcMMNdpcUEW639fubtPWd70h9+tA9AQD0flGxz8mJEydUVFSk9evXR7oU27hc9mzS8cnIkJYvlw4ckH73O/veBwAAuyVFugBJuv/++7Vhwwb179+/y7FFRUUqKipqvV9dXa3i4mLLa6qvr7f0dT/55O+UnX1OxcUHLHvNS119dYpSUubq61+vVXLyfiWEED2tnm80681z9XjEeu1EPM2XucaueJuvP4ZphmcjgMPh0M6dO5Wbm9vhscsuu0wDBw6UJNXU1Kiurk5z5swJauVkZGSosrLS8nqLi4s1f/58S16rudm7w+rnPy9t327JSwb0jW9IP/qR93bcOO8fMsPw3nb29Z/+9L6mTZsa1FjD8G468nisv/X9a26279+pU59o9Oh0JSfLln+NjVJ9vVRXF9xtKGObmryHjvftK6WmBv7ne9zt/kjjxo0O+Pil/1JSvD9Hvt8KgW6DGePvOaEyjNDGHzz4nqZPn27b61863ur7oXj33Xc1c+bMwANMs/0/SaYM75sahvdrP0/pallX69M3p7a3/paFMvadd/5Ps2ZdHfA9u6opWjZ1+/v8+Pvat26DGR8Oc+ZIaWnWv25nf7+jonPi9h3KIum5557Tzp07td3uv+JhVF3t/WFq3azz6KPShg0dB/r7TRXisg2m9P8kmY9775v69JeQ7+tL70vS3E4e8/e8Dm+vjp+WS5cFMybQss6EOt6ftnO6dH6h3jfafcdMJcjT6f22yxKMzsfIkOSRVCuZtZesE1Otz2pbl/k//tdpZ8u6+72zUnfW67Vtvg60Tq362g5t13tXX18bYHmCPEoI8nvX9qfM+6z2P3WXLutqjOT/5yjQY8E+544Qv49W/E6w2qWfZ98/f4/lBlgeaLy/97JyWdXrf1bWjWNDm3AP2R5OHnzwQf32t7/VyZMnlZ+fr/79++tvf/ubCgoKtG7dOs2YMcPuEiKuwwnYXn3V2x64/vqOgwNF4iCXJ0hKrTNVX6fW/zEZpimZ3vtm6/+kPn1cpqma2lr1S0u75H9b7ceYanPfMLy/Onz/u5FkGka73GT4BrQZowRDbZ7m/cL3Wm2HJ3z6+q23nX3dssDwva+fr3231dXVGjR4sHcqHsn0mJ9Os83XHlNSy32P7z+fbceakmma3tdoc98wDBmJhozEBCUkeL9O8N1v+dr7r+V+kiEjwZDha0v52lSG4f9+2/Xg7+uWW9Nj6lTVaV02eKiam01vV6rZlKfZlNkseTymPK233q9Nj9lm5bRZb5fyLTTN9usyAN+fmU4Hyfsz1LnAj5uSamtq1K9/f+/PfLtHWp4d8L+f7Zcb/sZf+ku7q/+td/6wnwGmTCNBZktXo7nlaxmGTCNBktFy37v8fE2t+g8c+OlytYwzvPd9z/HdN1rn3PI7QaYM09Py++HT5Ya8HwzfGLUsM8z2y1tvPR61RomW753R9uew3fex5feK2v+8GpeOazteUkNdnfqEfKhjMD/IYdDy+9JXhNn6OW779aePmYah2gt16tuvX8viS8d+2lIyW3/BdZyc38+S389X18+9bFRq1/O0mtnLjR492pbX3b17t2WvtX+/99O/YUPLgsGDTfOGGyx7fStYOd9ox1xjVzzNl7nGrniZb2d/v6PiaJ1Y1+6KxGfOeLfzjBsX0ZoAAIhWhJMwaHdF4uPHvXcIJwAA+EU4CYN2nROn03uHcAIAgF+EkzBo1zkhnAAA0CnCSRj47ZxkZ0esHgAAohnhJAx8nZMhQ+QNJ/37S5dfHtGaAACIVoSTMHC7pX79vBfmk9Pp3aTTk1NDAgAQwwgnYeBytWzSaWyUysvZ3wQAgE4QTsLA7W7ZGbaiwntxF8IJAAABEU7CwO3mMGIAAIJFOLFZU5N09iyHEQMAECzCic3OnPHe0jkBACA4hBObdTgBm2FIWVkRrQkAgGhGOLFZuxOwHT8ujR4tpUbg8tMAAPQShBObdeicsEkHAIBOEU5s5uucpKeckaqrCScAAHSBcGIzX+dkZB3X1AEAIBiEE5v5OieXn+NIHQAAgkE4sZkvnAx2E04AAAgG4cRmvs06fU8STgAACAbhxGZutzRwoJRY5vRemnjYsEiXBABAVCOc2MzluuQwYsOIdEkAAEQ1wonN3G5p2JAm6cMP2aQDAEAQCCc2c7mkif0qpOZmwgkAAEEgnNjo4kWppkbKSTzuXUA4AQCgS4QTG/muSDxOHKkDAECwCCc28h1GnNFIOAEAIFiEExv5TsA2otbpPUrH4YhoPQAA9AaEExu1XpH4rFMaPVpKTY1sQQAA9AKEExv5OicDTzvZpAMAQJAIJzZyuaTBOqOUmjOEEwAAgkQ4sZHbLY1VqfcO4QQAgKAQTmzkcnEYMQAAoSKc2MjtJpwAABAqwomN3G5pUgrhBACAUBBObORySeMTnVJamjR8eKTLAQCgVyCc2MjtlsZ6jnu7JoYR6XIAAOgVCCc2qj7dpJEXP2STDgAAIUiKdAGxqr5eGlpXoUQ1S9nZkS4HAIBew/bOyUMPPSSHwyHDMFRSUuJ3zLZt2zRt2jTl5uZqypQp2rhxo91l2Y4jdQAA6B7bw8miRYu0b98+ZWVlBRyTkZGh1157TSUlJdq3b5+eeOIJvf3223aXZivCCQAA3WN7OJk7d64yMjI6HXPddddpxIgRkqRBgwZp4sSJKi0ttbs0W3ECNgAAuscwTdMMxxs5HA7t3LlTubm5nY47cuSIrr/+eh0+fFijRo3q8HhRUZGKiopa71dXV2vHjh2W11tfX6/UHlxF+O23h+uKR9frC3pZv//P/5QnJcXC6qzX0/n2Jsw1dsXTfJlr7IqX+RYWFqqystL/g2aYZGVlmYcPH+50TEVFhTl+/Hjz5ZdfDvp1R48e3dPS/Nq9e3ePnv/zn5vmO5ph1g21pz6r9XS+vQlzjV3xNF/mGrviZb6d/f2OmkOJT5w4ofz8fK1evVp33nlnpMvpMd9mnYtj2KQDAEAooiKcfPzxx7r55pv1zW9+U/fee2+ky7HEhRPVGiq3NJZwAgBAKGwPJw8++KAyMjJUWVmp/Px8jR8/XpJUUFCgAwcOSJLWrFmj8vJyPfHEE8rLy1NeXp62bt1qd2m2SvjQu0Nv0gTCCQAAobD9JGybNm3Spk2bOizftWtX69fPPPOMnnnmGbtLCau+H3uP1EmdRDgBACAUUbFZJxYNOHVckpQwnnACAEAoCCc2uews5zgBAKA7CCc2Sa91qi4hTUpPj3QpAAD0KoQTm2RcdOqTtHGSYUS6FAAAehXCiQ3qzjcp0/xQrsFs0gEAIFSEExtUl1QqWU06fznhBACAUBFObHChxLszbN1IwgkAAKEinNig8QNvOGnKJJwAABAqwokdnN5wwjlOAAAIHeHEBskV3nCSkuOIbCEAAPRChBMb9D3p1EcapcEj+0a6FAAAeh3CiQ0GuZxyapyGDo10JQAA9D6EE6udPat+dS45NU6XXRbpYgAA6H0IJ1Zr2Rm21MjWoEERrgUAgF6IcGK1lnDySb9xnLkeAIBuIJxYrSWcVF/GYcQAAHQH4cRqLeHk/DDCCQAA3ZEU6QJijel0qk59pfT0SJcCAECvROfEYubxlsOIL2eHEwAAuoNwYqXmZhkflnEYMQAAPUA4sVJlpYymJk7ABgBADxBOrNSyMyydEwAAuo9wYqU24YTOCQAA3UM4sRKdEwAAeoxwYqXjxyVJpRpL5wQAgG4inFjJ6dTZfqNUr750TgAA6CbCiZWcTn3Sz3tmWMIJAADdQzixytmzksulypRxSkqSBgyIdEEAAPROhBOrlJZ6bwzvzrBckRgAgO4hnFil5Uido80cRgwAQE8QTqzSEk7+fIHDiAEA6AnCiVVawsn75+mcAADQE4QTqzidMlNTVdk8gs4JAAA9QDixitOpxjHjJBl0TgAA6AHCiRWam6WyMl0YwTlOAADoKcKJFT76SGps1LmhhBMAAHqKcGKFlmvqVA3KliQ26wAA0AOEEyu0HKlzsi+dEwAAesr2cPLQQw/J4XDIMAyVlJQEHPe9731P2dnZys7O1sMPP2x3WdZqCScVyd5wQucEAIDusz2cLFq0SPv27VNWVlbAMW+++aZefPFF/elPf9KRI0f02muvqbi42O7SrNMSTpwehyQ6JwAA9ITt4WTu3LnKyMjodMy2bdu0bNky9evXT3369NF9992nF1980e7SrON0SiNH6pPzaZLonAAA0BNRsc9JeXl5u86Kw+FQeXl5BCsKkdMpjRsnl0tKSZHS0iJdEAAAvVdSpAvwMdpcxtc0zYDjioqKVFRU1Hq/urralk1A9fX1Qb1uYm2t8k+f1kdTp8rpPKP+/fvqv/97r+X12C3Y+cYC5hq74mm+zDV2xdt8/YmKcJKZmamysrLW+x9++KEyMzP9jl25cqVWrlzZej8jI0Pz58+3vKbi4uLgXvf99yVJo+fMUfOLQzRypGypx25BzzcGMNfYFU/zZa6xK97m609UbNa588479Ytf/EK1tbVqaGjQli1btGTJkkiXFZyWnWE1bpzcbnaGBQCgp2wPJw8++KAyMjJUWVmp/Px8jR8/XpJUUFCgAwcOSJJuvPFGLV68WFOmTNGkSZM0b9483XLLLXaXZo2WcOJxeMMJO8MCANAztm/W2bRpkzZt2tRh+a5du9rdX7NmjdasWWN3OdZrCSfnh42Tx0PnBACAnoqKzTq92vHjUmqqXCkjJdE5AQCgpwgnPeU7jNjtPdqIzgkAAD1DOOmJ5maprKx1Z1iJzgkAAD1FOOmJjz6SGhtbT8Am0TkBAKCnCCc9cclhxBLhBACAniKc9ESbcOLrnLBZBwCAniGc9ASdEwAALEc46QlfOBk7lh1iAQCwCOGkJ5xOacQIKS1NLpeUmir17RvpogAA6N0IJz3Rco4TSZy6HgAAixBOuuv8eamqqjWcuFzsbwIAgBUIJ91VWuq9zc6WROcEAACrBB1ONm/erLNnz0ryXml4xowZevPNN20rLOodP+69HTdOzc3SmTN0TgAAsELQ4WTTpk0aNGiQ3n77bZWUlOj73/++vvGNb9hZW3Rrcxjx2bOSaRJOAACwQtDhJCkpSZL0v//7v7rnnns0f/58NTU12VZY1OMEbAAA2CLocJKQkKCXXnpJ27Zt08033yxJunjxom2FRT2n03vs8IgRnIANAAALBR1OfvrTn+qll17S/fffL4fDoaNHj+qmm26ys7bo5nRKY8dKCQmcgA0AAAslBTvwmmuu0auvvipJMk1TI0eO1MaNG20rLKo1N0tlZdJnPytJXJEYAAALBd05KSwsVHV1tS5evKi8vDylp6frySeftLO26HXihHTxYrsTsEl0TgAAsELQ4eS9997T4MGDVVxcrGnTpunkyZPavHmznbVFrzY7w0p0TgAAsFLQ4cQ0TUnSm2++qQULFmjgwIFKSIjTc7hdEk7onAAAYJ2g08WIESP01a9+Va+88ory8/PV2Nio5uZmO2uLXgE6J0OGRKgeAABiSNDh5IUXXtDEiRP10ksvafDgwfroo4+0cuVKO2uLXr5wMnasJG/nJC3Ne2QxAADomaDDyeWXX67ly5fLMAy98847Sk9P17Jly2wsLYo5ndKIEVK/fpK8nRM26QAAYI2gDyX+wx/+oEWLFik9PV2maaqqqkrbt2/Xtddea2d90en4cekzn2m963azMywAAFYJunOycuVKvfLKK/rjH/+oQ4cO6ZVXXtHXv/51O2uLTufPS1VVrfubSFyRGAAAKwUdTurr63Xddde13p89e7bq6upsKSqqlZZ6b1vCSVOTVF1N5wQAAKsEHU7S0tK0Z8+e1vtvvPGG+rXscxFXLjlSp7rae5fOCQAA1gh6n5Of/OQnWrhwofr06SPDMNTQ0KAXXnjBztqiEydgAwDAVkGHkxkzZuhvf/ubPvjgA5mmqQkTJmj8+PEqLy+3s77owwnYAACwVdDhRJKSk5OVm5vbet931ti44nRKffpII0dKonMCAIDVenT+ecMwrKqj93A6vSdfazl1v69zQjgBAMAaXXZOjhw5EvCxpqYmS4uJeh6P92id/PzWRb7OCZt1AACwRpfh5HOf+1zAx1Lj7XztJ05IFy92OMeJROcEAACrdBlOSn3n9cCnO8NmZ7cuYodYAACs1aN9TuLOJUfqSFyRGAAAqxFOQnH8uPf2ks06AwZIKSkRqgkAgBhDOAmFr3MydmzrIpeL/U0AALAS4SQUTqeUni61OW0/F/0DAMBatoeTY8eOafbs2crJydGsWbP8HppcX1+vZcuWacqUKcrNzdXtt9+u06dP211a6JzOdpt0JDonAABYzfZwsnz5cj3wwAM6evSoVq1apcLCwg5jNm/erJqaGv3pT39SSUmJ0tPTtWHDBrtLC01NjXTqVLtw0tgonT9POAEAwEq2hpNTp07p4MGDWrp0qSRp4cKFKi0tVVlZWYexFy5cUGNjo5qamlRTU6OMjAw7Swud75DqNuHkzBnvLZt1AACwTkjX1glVRUWFRo0apaQk79sYhqHMzEyVl5fL4XC0jlu+fLn279+v4cOHKzExUVdffbX+6Z/+ye9rFhUVqaioqPV+dXW1iouLLa+9vr6+3esO279fV0k6XFurEy3Ly8v7SZqjM2eOq7j4b5bXEE6XzjeWMdfYFU/zZa6xK97m65dpowMHDpiTJ09ut2zGjBnm3r172y373e9+Zy5ZssSsq6szGxoazC9+8YvmI488EtR7jB492qpy29m9e3f7BUVFpimZZpva9+3zLioqsqWEsOow3xjGXGNXPM2XucaueJlvZ/dDsAkAABZ5SURBVH+/bd2sM2bMGFVWVrZeg8c0TVVUVCgzM7PduKeeekr/8A//oNTUVKWkpOiuu+7S66+/bmdpoevkBGzscwIAgHVsDSfDhw/XtGnT9Pzzz0uSduzYIYfD0W6TjiSNGzdOxcXFMk1Tpmlq586dys3NtbO00DmdUp8+0qhRrYs4dT0AANaz/WidzZs3a/PmzcrJydH69ev17LPPSpIKCgp04MABSdLatWt19uxZXXHFFcrNzdXp06f16KOP2l1aaJxO78nXEj79ltE5AQDAerbuECtJEyZM0P79+zss37VrV+vXl112mbZv3253Kd3n8XiP1rn55naLuSIxAADW4wyxwThxQmpo8HsCNonNOgAAWIlwEgw/O8NKn3ZOuCIxAADWIZwEo5NwMmiQlGT7xjEAAOIH4SQYAcIJ19UBAMB6hJNg+MLJ2LHtFnNFYgAArEc4CYbTKQ0fLvXv324xnRMAAKxHOAmG09lhk05Dg1RbS+cEAACrEU66UlsrffJJwCN16JwAAGAtwklXSku9t4QTAADCgnDSFd/OsNnZ7RZzAjYAAOxBOOlKFydgo3MCAIC1CCdd6SKc0DkBAMBahJOuHD8upaRIo0a1W8wViQEAsAfhpCtOp/fkawntv1V0TgAAsAfhpDMej/donUs26Uh0TgAAsAvhpDMff+w925qfcOJ2S4YhDR4cgboAAIhhhJPOBNgZVvJ2TgYPlhITw1wTAAAxjnDSmU7CidvNJh0AAOxAOOlMF50TdoYFAMB6hJPO+MLJ2LEdHqJzAgCAPQgnnXE6peHDpQED2i2uq/P+o3MCAID1CCedcToD7m8i0TkBAMAOhJMAEurrpZMnOw0ndE4AALAe4SSAtJMnvV9wAjYAAMKKcBJA348/9n5B5wQAgLAinARA5wQAgMggnAQQTOeEcAIAgPUIJwH0PXlSSkmRRo3q8Jivc8JmHQAArEc4CSDt5EnJ4fB78Rw6JwAA2Idw4o/H4+2c+NmkI3nDSUKCNGhQmOsCACAOEE78OXlSiRcvBgwnLpc0ZIg3oAAAAGvx59Uf3zV1srP9Pux2s78JAAB2IZz408nViCVv54T9TQAAsAfhxJ+zZ9WckuI3nJgmnRMAAOyUFOkCotLXvqY948drfm5uh4cuXJAaGuicAABgFzongSQk+N3jlcOIAQCwF+EkRFxXBwAAexFOQsR1dQAAsJft4eTYsWOaPXu2cnJyNGvWLB05csTvuL1792rmzJm64oorNHHiRO3fv9/u0rqFzgkAAPayfYfY5cuX64EHHtCyZcu0fft2FRYWdggeJ06c0L333qvXXntNkyZNUn19verr6+0urVvonAAAYC9bOyenTp3SwYMHtXTpUknSwoULVVpaqrKysnbjnnzySS1dulSTJk2SJKWmpmrw4MF2ltZtdE4AALCXrZ2TiooKjRo1SklJ3rcxDEOZmZkqLy+Xw+FoHXfkyBGNHTtW+fn5On36tK6//no99thjSktL6/CaRUVFKioqar1fXV2t4uJiy2uvr6/3+7rvvZcjaaxKSt7U6dN1lr9vpASabyxirrErnubLXGNXvM3XL9NGBw4cMCdPntxu2YwZM8y9e/e2W7ZgwQLzqquuMt1ut9nY2Gjefffd5r/+678G9R6jR4+2rN62du/e7Xf5l79smpJpVlfb8rYRE2i+sYi5xq54mi9zjV3xMt/O/n7bullnzJgxqqysVFNTky8IqaKiQpmZme3GZWVl6XOf+5yGDBmipKQkLVmyRO+8846dpXWbyyUlJkoDB0a6EgAAYpOt4WT48OGaNm2ann/+eUnSjh075HA42m3SkaQvfelLev3119XQ0CBJ2r17t6ZOnWpnad3mdnt3hjWMSFcCAEBssv1Q4s2bN2vz5s3KycnR+vXr9eyzz0qSCgoKdODAAUnS7NmzddtttykvL09TpkxRVVWV1q1bZ3dp3cJ1dQAAsJfthxJPmDDB7zlLdu3a1e7+qlWrtGrVKrvL6TGXS8rOjnQVAADELs4QGwKuSAwAgP0IJyGoqZEaGzkBGwAAdiKchIATsAEAYD/CSQg4dT0AAPYjnITA1zkhnAAAYB/CSQh8nRM26wAAYB/CSQjonAAAYD/CSQjYIRYAAPsRTkLADrEAANiPcBICOicAANiPcBICl0tKTpb69Yt0JQAAxC7CSQh8p67nisQAANiHcBICl4v9TQAAsBvhJARuN+EEAAC7EU6CxBWJAQAID8JJkM6dk5qb6ZwAAGA3wkmQOIwYAIDwIJwEiROwAQAQHoSTINE5AQAgPAgnQaJzAgBAeBBOgkTnBACA8CCcBInOCQAA4UE4CZKvc0I4AQDAXoSTILFZBwCA8CCcBMnlkvr0kfr2jXQlAADENsJJkLgiMQAA4UE4CRJXJAYAIDwIJ0Hion8AAIQH4SQIHo905gydEwAAwoFwEoSzZ70Bhc4JAAD2I5wEgROwAQAQPoSTIHACNgAAwodwEgROwAYAQPgQToLAZh0AAMKHcBIEOicAAIQP4SQIdE4AAAgfwkkQ6JwAABA+hJMg+DonQ4ZEtg4AAOKB7eHk2LFjmj17tnJycjRr1iwdOXIk4Niqqiqlp6dr0aJFdpcVErfbezVirkgMAID9bA8ny5cv1wMPPKCjR49q1apVKiwsDDh2xYoVKigosLukkLlcbNIBACBcbA0np06d0sGDB7V06VJJ0sKFC1VaWqqysrIOY1944QWlp6frhhtusLOkbnG72RkWAIBwsTWcVFRUaNSoUUpKSpIkGYahzMxMlZeXtxt34sQJFRUVaf369XaW021ckRgAgPBJsvsNDMNod980zQ5j7r//fm3YsEH9+/fv8vWKiopUVFTUer+6ulrFxcU9L/QS9fX1Ki4uVnOzVF09T42Nn6i4+H3L3yda+OYbD5hr7Iqn+TLX2BVv8/XLtNEnn3xiDhw40GxsbDRN0zQ9Ho+Znp5ulpaWths3ZMgQMysry8zKyjKHDh1qpqWlmfPmzQvqPUaPHm112aZpmubu3btN0zTN06dNUzLNBx6w5W2ihm++8YC5xq54mi9zjV3xMt/O/n7bulln+PDhmjZtmp5//nlJ0o4dO+RwOORwONqNc7vdKisrU1lZmR5//HHdeuutUZMaOQEbAADhZfvROps3b9bmzZuVk5Oj9evX69lnn5UkFRQU6MCBA3a/fY9xAjYAAMLL9n1OJkyYoP3793dYvmvXLr/jly1bpmXLltlcVfDonAAAEF6cIbYLvs4J4QQAgPAgnHTB1zlhsw4AAOFBOOkCnRMAAMKLcNIFdogFACC8CCddYIdYAADCi3DSBbdb6t9fSkmJdCUAAMQHwkkXXC66JgAAhBPhpAtc9A8AgPAinHSBzgkAAOFFOOlEY6N07hzhBACAcCKcdKK62nvLZh0AAMKHcNIJDiMGACD8CCed4ARsAACEH+GkE3ROAAAIP8JJJ+icAAAQfoSTTtA5AQAg/AgnnaBzAgBA+BFOOkHnBACA8COcdMLXORkyJLJ1AAAQTwgnnXC7pYEDpeTkSFcCAED8IJx0guvqAAAQfoSTTnBFYgAAwo9w0gk6JwAAhB/hJIDGRkM1NXROAAAIN8JJAOfPe/eCpXMCAEB4EU4C8IUTOicAAIQX4SQAOicAAEQG4SQAwgkAAJFBOAmAzToAAEQG4SSAc+dSJNE5AQAg3AgnAdA5AQAgMggnAZw7xz4nAABEAuEkAF/nhCsSAwAQXoSTAM6fT9bgwVJiYqQrAQAgvhBOAjh/PplNOgAARADhJIBz55LZGRYAgAggnARA5wQAgMggnPhRXy81NCTROQEAIAIIJ3643d5bOicAAISf7eHk2LFjmj17tnJycjRr1iwdOXKkw5ht27Zp2rRpys3N1ZQpU7Rx40a7y+qUL5zQOQEAIPxsDyfLly/XAw88oKNHj2rVqlUqLCzsMCYjI0OvvfaaSkpKtG/fPj3xxBN6++237S4tIJfLe0vnBACA8LM1nJw6dUoHDx7U0qVLJUkLFy5UaWmpysrK2o277rrrNGLECEnSoEGDNHHiRJWWltpZWqfonAAAEDlJdr54RUWFRo0apaQk79sYhqHMzEyVl5fL4XD4fc6RI0e0f/9+Pf30034fLyoqUlFRUev96upqFRcXW1r33r2jJeWqtPQ9FReftvS1o1V9fb3l38doxVxjVzzNl7nGrnibrz+2hhPJG0jaMk0z4NjKykr9/d//vZ566imNGjXK75iVK1dq5cqVrfczMjI0f/58a4pt8f773tvPfna6rr7a0peOWsXFxZZ/H6MVc41d8TRf5hq74m2+/tgaTsaMGaPKyko1NTUpKSlJpmmqoqJCmZmZHcaeOHFC+fn5Wr16te688047y+rSP/6jNHToW7ryyusjWgcAAPHI1n1Ohg8frmnTpun555+XJO3YsUMOh6PDJp2PP/5YN998s775zW/q3nvvtbOkoAwYIGVkXFDfvpGuBACA+GP70TqbN2/W5s2blZOTo/Xr1+vZZ5+VJBUUFOjAgQOSpDVr1qi8vFxPPPGE8vLylJeXp61bt9pdGgAAiEK273MyYcIE7d+/v8PyXbt2tX79zDPP6JlnnrG7FAAA0AtwhlgAABBVCCcAACCqEE4AAEBUIZwAAICoQjgBAABRhXACAACiCuEEAABEFcIJAACIKoQTAAAQVQgnAAAgqhBOAABAVCGcAACAqGKYpmlGuoie6NOnj4YNG2b569bU1Kh///6Wv260iqf5MtfYFU/zZa6xK17mW1VVpYaGBr+P9fpwYpeMjAxVVlZGuoywiaf5MtfYFU/zZa6xK97m6w+bdQAAQFQhnAAAgKiSuHbt2rWRLiJaXXvttZEuIaziab7MNXbF03yZa+yKt/lein1OAABAVGGzDgAAiCqEEwAAEFXiOpwcO3ZMs2fPVk5OjmbNmqUjR474Hfe9731P2dnZys7O1sMPPxzmKq1RX1+vO+64Qzk5OcrLy9Mtt9yisrKyDuPeeOMNpaWlKS8vr/VfXV1d+AvuIYfDoYkTJ7bOYdu2bX7H9fZ1W11d3W5d5eTkKCkpSW63u9243rxeH3roITkcDhmGoZKSktblwX5+pd6znv3NNdjPrtS71nOg9RrsZ1fqPetV8j/fYD+/Uu9at5Yw49hNN91kbt261TRN03zllVfMa665psOYvXv3mpMnTzZramrM+vp6c/r06ebu3bvDXGnP1dXVmf/1X/9lejwe0zRNc+PGjeZnP/vZDuNef/11c/r06eEuz3JZWVnm4cOHOx0TK+u2rR/+8IfmggULOizvzet17969ZkVFRYd1Gszn1/f83rKe/c012M+uafau9RxovQbz2fU9v7esV9MMPN+2An1+TbN3rVsrxG3n5NSpUzp48KCWLl0qSVq4cKFKS0s7/I9k27ZtWrZsmfr166c+ffrovvvu04svvhiBinsmNTVVBQUFMgxDknTNNdfI6XRGuKrIipV129bWrVtVWFgY6TIsNXfuXGVkZLRbFuznV+pd69nfXGP1s+tvrqHoTetVCm6+sfj57a64DScVFRUaNWqUkpKSJEmGYSgzM1Pl5eXtxpWXlysrK6v1vsPh6DCmN/rJT36i2267ze9jH3zwga666irNnDlTTz75ZJgrs85dd92lKVOm6Ctf+Yqqqqo6PB5r63b//v1yuVxasGCB38djZb1KwX9+pdhbz519dqXYWM9dfXal2FuvXX1+pdhYt8FKinQBkeT7n4iPGeCo6rbjAo3pTX7wgx/o2LFjeuqppzo8dtVVV6myslKDBg1SZWWlCgoKdPnll2vx4sURqLT73nzzTWVmZqqxsVGrV6/Wvffeq127dnUYF0vrdsuWLbrnnnta/2C3FSvrta1gP7+Xju3N67mzz64UG+s52M+uFDvrVer88yvFxroNRdx2TsaMGaPKyko1NTVJ8v5gV1RUKDMzs924zMzMdq3iDz/8sMOY3uTxxx/Xr3/9a7322mtKS0vr8PjAgQM1aNAgSd7rO3zxi1/UW2+9Fe4ye8y3jpKTk/Uv//IvfucQS+u2trZW27Zt03333ef38VhZrz7Bfn6l2FnPXX12pdhYz8F8dn3jYmG9Sl1/fqXYWLehiNtwMnz4cE2bNk3PP/+8JGnHjh1yOBxyOBztxt155536xS9+odraWjU0NGjLli1asmRJBCruuaKiIr344ov6/e9/r8GDB/sd8/HHH8vj8UiSzp8/r507d2ratGnhLLPHamtrVV1d3Xr/xRdf9DuHWFq3r7zyiq688kpNnDjR7+OxsF7bCvbzK8XGeg7msyv1/vUc7GdXio316tPV51fq/es2ZJHbFzfy/vrXv5rXXHON+ZnPfMacPn26WVJSYpqmad56663mu+++2zruu9/9rjl27Fhz7Nix5re//e1IldsjFRUVpiRz3Lhx5tSpU82pU6eas2bNMk3TNAsLC83f/va3pml6jwSYPHmyeeWVV5qTJ082H3nkkdajBHqL48ePm3l5eeaUKVPM3Nxc8/bbbzdLS0tN04zNdWuapjlnzhxzy5Yt7ZbFynpdsWKFOXr0aDMxMdFMT083s7OzTdMM/Pk1zd67nv3NtbPPrmn23vXsb66dfXZNs/euV9MM/HNsmv4/v6bZe9etFTh9PQAAiCpxu1kHAABEJ8IJAACIKoQTAAAQVQgnAAAgqhBOAABAVCGcAACAqBLXp68HYD2Hw6HU1FSlpqa2LvvVr36lyZMnW/YeZWVlmjFjhk6fPm3ZawKIHoQTAJbbvn27cnNzI10GgF6KzToAwsIwDK1du1bXXXedcnJy2l3efvfu3brqqqt05ZVX6oYbbtCRI0daH9u6davy8vI0depUzZgxo931VNasWaPp06dr/PjxrReHq6ur0xe+8AVNnjxZU6dO1bx588I2RwDWoHMCwHKLFi1qt1nnnXfekeQNKG+//bacTqdmzZqlOXPmqE+fPlq6dKlef/11TZkyRS+88IIWL16skpISvfHGG/r+97+vt956SyNHjtSFCxckSadOnZLL5dL06dO1bt067d69W//8z/+sgoIC7d69W2fOnGkNOG63O/zfAAA9wunrAVjK4XBo586dHTbrGIahyspKjR49WpJ0xx13aPHixRowYICeeOIJ7dmzp3Xs4MGD9Ze//EVFRUUaMGCA1qxZ0+61ysrKlJubq5qaGknS2bNnNXToUDU1NcnpdOrGG2/UggULdMMNN6igoEADBgywedYArMRmHQARYxiGTNOUYRh+H+tM285MYmKimpubJUnjxo3TkSNHdMstt+jtt99Wbm6uzpw5Y23hAGxFOAEQNlu2bJHk7Xzs27dPc+bM0bXXXqtDhw7pL3/5iyTppZdeUkZGhkaMGKHbbrtNv/zlL3Xy5ElJ0oULF1o37QRSWVkpwzB0++236/HHH5dpmqqoqLB3YgAsxT4nACx36T4nGzdulCT16dNH1113naqqqrRx40aNGTNGkvQf//Efuuuuu9Tc3KzBgwfr5ZdfliTNnTtXq1ev1rx582QYhlJSUrR9+/ZO3/vw4cP61re+JdM05fF4dPfdd+vKK6+0aaYA7MA+JwDCwjAMnT9/Xv379490KQCiHJt1AABAVGGzDoCwoEkLIFh0TgAAQFQhnAAAgKhCOAEAAFGFcAIAAKIK4QQAAEQVwgkAAIgq/x+ML7QTIF3GDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(np.array(loss_values_train), 'b')\n",
    "plt.plot(np.array(loss_values_val), 'r')\n",
    "plt.legend(['Train','Val'])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('fasttext/train_curve_feedback-v1_POS.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 25.00%\n"
     ]
    }
   ],
   "source": [
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 - World\n",
      "1 - Sports\n",
      "2 - Business\n",
      "3 - Sci/Tech\n",
      "\n",
      "119909\n",
      "Printing Train + Val Number of Documents Found\n",
      "120000\n",
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n",
      "---Printing Parameters Finished!---\n",
      "Test Accuracy : 91.12%\n",
      "channels_last\n",
      "['conv1' 'fc1' 'fc2' 'fc3']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, None, 300, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, 1, 1024)     922624    \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_3 (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,193,380\n",
      "Trainable params: 1,193,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LEARNINGRATE = 5e-3\n",
    "GAMMA = 0.9\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "NUMEPOCHS = 20\n",
    "\n",
    "\n",
    "dset = CustomDataset.get_dataset('data/train.csv')\n",
    "tset = CustomDataset.get_dataset('data/test.csv')\n",
    "\n",
    "print('''\n",
    "0 - World\n",
    "1 - Sports\n",
    "2 - Business\n",
    "3 - Sci/Tech\n",
    "''')\n",
    "\n",
    "### TRAIN VAL SPLIT\n",
    "\n",
    "NUM_DATA_POINTS = len(dset)\n",
    "\n",
    "indices = list(range(NUM_DATA_POINTS))\n",
    "split = int(np.floor(0.2 * NUM_DATA_POINTS))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(indices[0])\n",
    "\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_points = len(train_indices)\n",
    "val_points = len(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE, \n",
    "                                           sampler=train_sampler, num_workers=4)\n",
    "validation_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE,\n",
    "                                                sampler=valid_sampler, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(tset, batch_size = BATCHSIZE,\n",
    "                                                num_workers=4)\n",
    "\n",
    "print(\"Printing Train + Val Number of Documents Found\")\n",
    "print(NUM_DATA_POINTS)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/weights_2/Model_quicksave5.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model.eval()\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        #print(param.shape)\n",
    "print('---Printing Parameters Finished!---')\n",
    "\n",
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from keras.layers import Conv2D, Input, Dense, MaxPool2D, Flatten, Lambda, GlobalMaxPool2D, Dropout\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import innvestigate\n",
    "import innvestigate.applications\n",
    "import innvestigate.applications.mnist\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.utils.tests.networks import base as network_base\n",
    "\n",
    "print(K.image_data_format())\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    inp = Input((None,300,1))\n",
    "    x = Conv2D(1024,(3,300),activation='relu', name='conv1')(inp)\n",
    "    x = GlobalMaxPool2D('channels_last')(x)\n",
    "    x = Dense(256,name='fc1',activation='relu')(x)\n",
    "    z = Dropout(0.25)(x)\n",
    "    ou = Dense(32,name='fc2',activation='relu')(z)\n",
    "    ou = Dropout(0.3)(ou)\n",
    "    out = Dense(4,name='fc3')(ou)\n",
    "    outz = Dropout(0.2)(out)\n",
    "    k_model = Model(inp, outz)\n",
    "\n",
    "\n",
    "trained_weights = model.state_dict()\n",
    "\n",
    "pytorch_layers = [] # get ptroch layers names and suffixes\n",
    "for x, l in zip(trained_weights, k_model.layers):\n",
    "    pytorch_layers.append(x[:x.find('.')])\n",
    "\n",
    "unique_layers = np.unique(pytorch_layers)\n",
    "print(unique_layers)\n",
    "\n",
    "\n",
    "for layer in unique_layers:\n",
    "    weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "    biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "    if 'bn' in layer:\n",
    "        running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "        running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "        W = [weights, biases, running_mean, running_var]\n",
    "    elif 'fc' in layer:\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        W = [weights.T, biases]\n",
    "    else:\n",
    "        W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "    k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "k_model.summary()\n",
    "\n",
    "method = (\"lrp.z\",{},\"LRP-Z\")\n",
    "         \n",
    "analyzer = innvestigate.create_analyzer(method[0], k_model,neuron_selection_mode=\"index\",**method[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 91.12%\n"
     ]
    }
   ],
   "source": [
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  1024\n",
      "epoch [1/10] Forced Epoch loss:0.1228521, train acc:93.5969, val loss:0.3572898, val acc:87.8208 in 0h 4m 2s\n",
      "epoch [2/10] Forced Epoch loss:0.1063987, train acc:94.0229, val loss:0.7207132, val acc:78.0250 in 0h 4m 3s\n",
      "epoch [3/10] Forced Epoch loss:0.1079340, train acc:94.0198, val loss:0.5827904, val acc:82.4292 in 0h 4m 2s\n",
      "epoch [4/10] Forced Epoch loss:0.1052362, train acc:93.8344, val loss:0.8558776, val acc:74.4375 in 0h 4m 10s\n",
      "epoch [5/10] Forced Epoch loss:0.1157998, train acc:93.7771, val loss:0.9470315, val acc:71.6417 in 0h 4m 10s\n",
      "epoch [6/10] Forced Epoch loss:0.1325644, train acc:93.2677, val loss:0.9213593, val acc:75.7833 in 0h 3m 53s\n",
      "epoch [7/10] Forced Epoch loss:0.1174845, train acc:93.7052, val loss:0.7745110, val acc:77.5833 in 0h 3m 52s\n",
      "epoch [8/10] Forced Epoch loss:0.1290279, train acc:93.4583, val loss:0.5882230, val acc:79.3417 in 0h 4m 11s\n",
      "epoch [9/10] Forced Epoch loss:0.1030741, train acc:94.1823, val loss:0.6085100, val acc:81.9667 in 0h 4m 10s\n",
      "epoch [10/10] Forced Epoch loss:0.1054744, train acc:94.0802, val loss:0.5335722, val acc:83.5792 in 0h 4m 11s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "NUMEPOCHS = 10\n",
    "top_n = 7\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    ##################\n",
    "    #print('At start')\n",
    "    #time.sleep(10)\n",
    "    mode = 'Forced Epoch'\n",
    "\n",
    "    for layer in unique_layers:\n",
    "        weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        if 'bn' in layer:\n",
    "            running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "            running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "            W = [weights, biases, running_mean, running_var]\n",
    "        elif 'fc' in layer:\n",
    "            biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "            W = [weights.T, biases]\n",
    "        else:\n",
    "            W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "        k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "    ############\n",
    "    #print('After model load')\n",
    "    #time.sleep(10)\n",
    "    for ib,sample in enumerate(train_loader):\n",
    "\n",
    "        data_input = sample['matrix'][:,None,:,:].numpy()\n",
    "        data_output = sample['class'][:,0].numpy()\n",
    "\n",
    "        for j in range(BATCHSIZE):\n",
    "            #index = train_indices[BATCHSIZE*ib+j]\n",
    "            #sample = dset[index]\n",
    "            try:\n",
    "                data = data_input[j]\n",
    "            except IndexError as error:\n",
    "                break\n",
    "\n",
    "            data = data.reshape((1, -1, 300,1))    \n",
    "            analysis = np.zeros(data.shape[1])\n",
    "\n",
    "            a = np.squeeze(analyzer.analyze(data,neuron_selection=data_output[j]))\n",
    "            a = np.sum(a, axis=1)\n",
    "\n",
    "            order = np.argsort(a)[::-1]\n",
    "            for k in order[top_n:]:\n",
    "                data_input[j,:,k,:] = np.zeros((1,1,300)) \n",
    "\n",
    "        data_input = torch.as_tensor(data_input)\n",
    "        data_output = torch.as_tensor(data_output)\n",
    "\n",
    "        data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "        data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "        output = model(data_input) \n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        loss = criterion(output, data_output)\n",
    "        runloss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        runloss += loss.item() * data_input.size(0)\n",
    "        tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "    runloss /= (train_points)\n",
    "    tacc = tacc*100.0/ (train_points)\n",
    "\n",
    "    loss_values_train.append(runloss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'fasttext/feedback-v2_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model.state_dict(), 'fasttext/feedback-v2_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(np.array(loss_values_train), 'b')\n",
    "plt.plot(np.array(loss_values_val), 'r')\n",
    "plt.legend(['Train','Val'])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('fasttext/train_curve_feedback-v2_POS.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Test Accuracy : 86.43%\n",
      "Test Accuracy : 76.47%\n",
      "Test Accuracy : 81.53%\n",
      "Test Accuracy : 73.68%\n",
      "Test Accuracy : 71.57%\n",
      "Test Accuracy : 75.11%\n",
      "Test Accuracy : 77.20%\n",
      "Test Accuracy : 78.30%\n",
      "Test Accuracy : 81.04%\n",
      "Test Accuracy : 83.12%\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "for i in range(10):\n",
    "    FILE = 'fasttext/feedback-v2_POS/Model_quicksave'+str(i+1)+'.pt'\n",
    "\n",
    "    model.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "    model.eval()\n",
    "\n",
    "    corr = 0.0\n",
    "    with torch.no_grad():\n",
    "      for ib,sample in enumerate(test_loader):\n",
    "\n",
    "        data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "        data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "        data_input = data_input.to(device, dtype=torch.float)\n",
    "        data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "        output = model(data_input)\n",
    "        _, preds = torch.max(output,dim=1)\n",
    "        corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "    print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 - World\n",
      "1 - Sports\n",
      "2 - Business\n",
      "3 - Sci/Tech\n",
      "\n",
      "14430\n",
      "Printing Train + Val Number of Documents Found\n",
      "120000\n",
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Initializing optimizer and scheduler..\n",
      "Optimizer and scheduler initialized.\n",
      "Printing Parameters\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n",
      "---Printing Parameters Finished!---\n",
      "Test Accuracy : 91.12%\n",
      "channels_last\n",
      "['conv1' 'fc1' 'fc2' 'fc3']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, None, 300, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, 1, 1024)     922624    \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_8 (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,193,380\n",
      "Trainable params: 1,193,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LEARNINGRATE = 3e-5\n",
    "GAMMA = 0.7\n",
    "\n",
    "BATCHSIZE = 1024\n",
    "NUMEPOCHS = 5\n",
    "\n",
    "\n",
    "dset = CustomDataset.get_dataset('data/train.csv')\n",
    "tset = CustomDataset.get_dataset('data/test.csv')\n",
    "\n",
    "print('''\n",
    "0 - World\n",
    "1 - Sports\n",
    "2 - Business\n",
    "3 - Sci/Tech\n",
    "''')\n",
    "\n",
    "### TRAIN VAL SPLIT\n",
    "\n",
    "NUM_DATA_POINTS = len(dset)\n",
    "\n",
    "indices = list(range(NUM_DATA_POINTS))\n",
    "split = int(np.floor(0.2 * NUM_DATA_POINTS))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(indices[0])\n",
    "\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_points = len(train_indices)\n",
    "val_points = len(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE, \n",
    "                                           sampler=train_sampler, num_workers=4)\n",
    "validation_loader = torch.utils.data.DataLoader(dset, batch_size = BATCHSIZE,\n",
    "                                                sampler=valid_sampler, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(tset, batch_size = BATCHSIZE,\n",
    "                                                num_workers=4)\n",
    "\n",
    "print(\"Printing Train + Val Number of Documents Found\")\n",
    "print(NUM_DATA_POINTS)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "FILE = 'fasttext/weights_2/Model_quicksave5.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "model.eval()\n",
    "\n",
    "print('Initializing optimizer and scheduler..')\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), lr = LEARNINGRATE)             # OR RAdam/DiffGrad/etc\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = GAMMA)\n",
    "\n",
    "print('Optimizer and scheduler initialized.')\n",
    "\n",
    "\n",
    "print('Printing Parameters')\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        #print(param.shape)\n",
    "print('---Printing Parameters Finished!---')\n",
    "\n",
    "corr = 0.0\n",
    "with torch.no_grad():\n",
    "  for ib,sample in enumerate(test_loader):\n",
    "\n",
    "    data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "    data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "    data_input = data_input.to(device, dtype=torch.float)\n",
    "    data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "    output = model(data_input)\n",
    "    _, preds = torch.max(output,dim=1)\n",
    "    corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from keras.layers import Conv2D, Input, Dense, MaxPool2D, Flatten, Lambda, GlobalMaxPool2D, Dropout\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import innvestigate\n",
    "import innvestigate.applications\n",
    "import innvestigate.applications.mnist\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.utils.tests.networks import base as network_base\n",
    "\n",
    "print(K.image_data_format())\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    inp = Input((None,300,1))\n",
    "    x = Conv2D(1024,(3,300),activation='relu', name='conv1')(inp)\n",
    "    x = GlobalMaxPool2D('channels_last')(x)\n",
    "    x = Dense(256,name='fc1',activation='relu')(x)\n",
    "    z = Dropout(0.25)(x)\n",
    "    ou = Dense(32,name='fc2',activation='relu')(z)\n",
    "    ou = Dropout(0.3)(ou)\n",
    "    out = Dense(4,name='fc3')(ou)\n",
    "    outz = Dropout(0.2)(out)\n",
    "    k_model = Model(inp, outz)\n",
    "\n",
    "\n",
    "trained_weights = model.state_dict()\n",
    "\n",
    "pytorch_layers = [] # get ptroch layers names and suffixes\n",
    "for x, l in zip(trained_weights, k_model.layers):\n",
    "    pytorch_layers.append(x[:x.find('.')])\n",
    "\n",
    "unique_layers = np.unique(pytorch_layers)\n",
    "print(unique_layers)\n",
    "\n",
    "\n",
    "for layer in unique_layers:\n",
    "    weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "    biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "    if 'bn' in layer:\n",
    "        running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "        running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "        W = [weights, biases, running_mean, running_var]\n",
    "    elif 'fc' in layer:\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        W = [weights.T, biases]\n",
    "    else:\n",
    "        W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "    k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "k_model.summary()\n",
    "\n",
    "method = (\"lrp.z\",{},\"LRP-Z\")\n",
    "         \n",
    "analyzer = innvestigate.create_analyzer(method[0], k_model,neuron_selection_mode=\"index\",**method[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size =  1024\n",
      "epoch [1/5] Forced Epoch loss:0.1348924, train acc:93.4510, val loss:0.1847103, val acc:93.9292 in 0h 4m 16s\n",
      "epoch [2/5] Forced Epoch loss:0.1219127, train acc:93.7031, val loss:0.1862043, val acc:94.0500 in 0h 4m 14s\n",
      "epoch [3/5] Forced Epoch loss:0.1113953, train acc:94.0719, val loss:0.1953512, val acc:93.9208 in 0h 4m 16s\n",
      "epoch [4/5] Forced Epoch loss:0.1083174, train acc:94.0333, val loss:0.2047176, val acc:93.8167 in 0h 4m 15s\n",
      "epoch [5/5] Forced Epoch loss:0.1075244, train acc:93.9542, val loss:0.2107031, val acc:93.7583 in 0h 4m 15s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "NUMEPOCHS = 5\n",
    "top_n = 6\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "loss_values_train = []\n",
    "loss_values_val = []\n",
    "\n",
    "print('Batch Size = ',BATCHSIZE)\n",
    "\n",
    "for epoch in range(1,NUMEPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    runloss = 0.0\n",
    "    tacc = 0\n",
    "    ##################\n",
    "    #print('At start')\n",
    "    #time.sleep(10)\n",
    "    mode = 'Forced Epoch'\n",
    "\n",
    "    for layer in unique_layers:\n",
    "        weights = trained_weights['{}.weight'.format(layer)].cpu().numpy() # torch weights (nf, ch, x, y)\n",
    "        biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "        if 'bn' in layer:\n",
    "            running_mean = trained_weights['{}.running_mean'.format(layer)].cpu().numpy()\n",
    "            running_var = trained_weights['{}.running_var'.format(layer)].cpu().numpy()\n",
    "            W = [weights, biases, running_mean, running_var]\n",
    "        elif 'fc' in layer:\n",
    "            biases = trained_weights['{}.bias'.format(layer)].cpu().numpy()\n",
    "            W = [weights.T, biases]\n",
    "        else:\n",
    "            W = [np.moveaxis(weights, [0, 1], [3, 2]), biases] # transpose to (x, y, ch, nf) keras version\n",
    "        k_model.get_layer(layer).set_weights(W)\n",
    "\n",
    "    ############\n",
    "    #print('After model load')\n",
    "    #time.sleep(10)\n",
    "    for ib,sample in enumerate(train_loader):\n",
    "\n",
    "        data_input = sample['matrix'][:,None,:,:].numpy()\n",
    "        data_output = sample['class'][:,0].numpy()\n",
    "\n",
    "        for j in range(BATCHSIZE):\n",
    "            #index = train_indices[BATCHSIZE*ib+j]\n",
    "            #sample = dset[index]\n",
    "            try:\n",
    "                data = data_input[j]\n",
    "            except IndexError as error:\n",
    "                break\n",
    "\n",
    "            data = data.reshape((1, -1, 300,1))    \n",
    "            analysis = np.zeros(data.shape[1])\n",
    "\n",
    "            a = np.squeeze(analyzer.analyze(data,neuron_selection=data_output[j]))\n",
    "            a = np.sum(a, axis=1)\n",
    "\n",
    "            order = np.argsort(a)[::-1]\n",
    "            for k in order[top_n:]:\n",
    "                data_input[j,:,k,:] = np.zeros((1,1,300)) \n",
    "\n",
    "        data_input = torch.as_tensor(data_input)\n",
    "        data_output = torch.as_tensor(data_output)\n",
    "\n",
    "        data_input = data_input.to(device, dtype=torch.float)  #, dtype=torch.float\n",
    "        data_output = data_output.to(device, dtype=torch.long)    #, dtype=torch.long\n",
    "\n",
    "        output = model(data_input) \n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        loss = criterion(output, data_output)\n",
    "        runloss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        runloss += loss.item() * data_input.size(0)\n",
    "        tacc += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "    runloss /= (train_points)\n",
    "    tacc = tacc*100.0/ (train_points)\n",
    "\n",
    "    loss_values_train.append(runloss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ib,sample in enumerate(validation_loader):\n",
    "            \n",
    "            data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "            data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "            data_input = data_input.to(device, dtype=torch.float)\n",
    "            data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "            output = model(data_input)\n",
    "            _, preds = torch.max(output,dim=1)\n",
    "            \n",
    "            loss = criterion(output, data_output)\n",
    "            val_loss += loss.item()* data_input.size(0)\n",
    "            corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "            \n",
    "    val_loss /= val_points\n",
    "    corr = corr*100.0/val_points\n",
    "    loss_values_val.append(val_loss)\n",
    "\n",
    "    if val_loss <= min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'fasttext/feedback-v2_POS/Model_best_val_quicksave.pt')\n",
    "\n",
    "    \n",
    "    stop_time = time.time()\n",
    "    time_el = int(stop_time-start_time)\n",
    "    \n",
    "\n",
    "    print('epoch [{}/{}] '.format(epoch, NUMEPOCHS)+mode+' loss:{:.7f}, train acc:{:.4f}, val loss:{:.7f}, val acc:{:.4f} in {}h {}m {}s'.format(\n",
    "                                                                                runloss, tacc, val_loss, corr,\n",
    "                                                                                time_el//3600,\n",
    "                                                                                (time_el%3600)//60,\n",
    "                                                                               time_el%60))\n",
    "    \n",
    "    torch.save(model.state_dict(), 'fasttext/feedback-v2_POS/Model_quicksave'+str(epoch)+'.pt')\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Building Master model..\n",
      "Model Built.\n",
      "Test Accuracy : 91.67%\n",
      "Test Accuracy : 92.01%\n",
      "Test Accuracy : 91.91%\n",
      "Test Accuracy : 91.78%\n",
      "Test Accuracy : 91.71%\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(True, WINDOW=3)\n",
    "print('Running on',device)\n",
    "print('Building Master model..')\n",
    "model.to(device)\n",
    "print('Model Built.')\n",
    "\n",
    "for i in range(5):\n",
    "    FILE = 'fasttext/feedback-v2_POS/Model_quicksave'+str(i+1)+'.pt'\n",
    "\n",
    "    model.load_state_dict(torch.load(FILE,map_location='cuda:0'))\n",
    "    model.eval()\n",
    "\n",
    "    corr = 0.0\n",
    "    with torch.no_grad():\n",
    "      for ib,sample in enumerate(test_loader):\n",
    "\n",
    "        data_input = torch.as_tensor(sample['matrix'][:,None,:,:])\n",
    "        data_output = torch.as_tensor(sample['class'][:,0])\n",
    "\n",
    "        data_input = data_input.to(device, dtype=torch.float)\n",
    "        data_output = data_output.to(device, dtype=torch.long)\n",
    "\n",
    "        output = model(data_input)\n",
    "        _, preds = torch.max(output,dim=1)\n",
    "        corr += (torch.sum(preds == data_output.data)).data.item()\n",
    "\n",
    "    print('Test Accuracy : {:.2f}%'.format(corr*100.0/len(tset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_ptorch",
   "language": "python",
   "name": "gpu_ptorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
