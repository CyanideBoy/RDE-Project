# Distilling-the-Knowledge-in-a-Neural-Network
This is an implementation of a part of the paper "Distilling the Knowledge in a Neural Network" (https://arxiv.org/abs/1503.02531). <br> 
This code is abridged from (https://github.com/shriramsb/Distilling-the-Knowledge-in-a-Neural-Network). <br>
<hline>
### Notes :
* Distill with respect to the other false classes' relevance maps as well.
* Test on a better dataset and models where effect of the distillation methods would be easily observed and concluded
